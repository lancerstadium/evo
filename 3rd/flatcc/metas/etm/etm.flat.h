#ifndef FLATBUFFERS_COMMON_READER_H
#define FLATBUFFERS_COMMON_READER_H

/* Generated by flatcc 0.6.2 FlatBuffers schema compiler for C by dvide.com */

/* Common FlatBuffers read functionality for C. */

#include "flatcc/flatcc_prologue.h"
#include "flatcc/flatcc_flatbuffers.h"


#define __flatbuffers_read_scalar_at_byteoffset(N, p, o) N ## _read_from_pe((uint8_t *)(p) + (o))
#define __flatbuffers_read_scalar(N, p) N ## _read_from_pe(p)
#define __flatbuffers_read_vt(ID, offset, t)\
flatbuffers_voffset_t offset = 0;\
{   flatbuffers_voffset_t id__tmp, *vt__tmp;\
    FLATCC_ASSERT(t != 0 && "null pointer table access");\
    id__tmp = ID;\
    vt__tmp = (flatbuffers_voffset_t *)((uint8_t *)(t) -\
        __flatbuffers_soffset_read_from_pe(t));\
    if (__flatbuffers_voffset_read_from_pe(vt__tmp) >= sizeof(vt__tmp[0]) * (id__tmp + 3u)) {\
        offset = __flatbuffers_voffset_read_from_pe(vt__tmp + id__tmp + 2);\
    }\
}
#define __flatbuffers_field_present(ID, t) { __flatbuffers_read_vt(ID, offset__tmp, t) return offset__tmp != 0; }
#define __flatbuffers_scalar_field(T, ID, t)\
{\
    __flatbuffers_read_vt(ID, offset__tmp, t)\
    if (offset__tmp) {\
        return (const T *)((uint8_t *)(t) + offset__tmp);\
    }\
    return 0;\
}
#define __flatbuffers_define_scalar_field(ID, N, NK, TK, T, V)\
static inline T N ## _ ## NK ## _get(N ## _table_t t__tmp)\
{ __flatbuffers_read_vt(ID, offset__tmp, t__tmp)\
  return offset__tmp ? __flatbuffers_read_scalar_at_byteoffset(TK, t__tmp, offset__tmp) : V;\
}\
static inline T N ## _ ## NK(N ## _table_t t__tmp)\
{ __flatbuffers_read_vt(ID, offset__tmp, t__tmp)\
  return offset__tmp ? __flatbuffers_read_scalar_at_byteoffset(TK, t__tmp, offset__tmp) : V;\
}\
static inline const T *N ## _ ## NK ## _get_ptr(N ## _table_t t__tmp)\
__flatbuffers_scalar_field(T, ID, t__tmp)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__flatbuffers_field_present(ID, t__tmp)\
__flatbuffers_define_scan_by_scalar_field(N, NK, T)
#define __flatbuffers_define_scalar_optional_field(ID, N, NK, TK, T, V)\
__flatbuffers_define_scalar_field(ID, N, NK, TK, T, V)\
static inline TK ## _option_t N ## _ ## NK ## _option(N ## _table_t t__tmp)\
{ TK ## _option_t ret; __flatbuffers_read_vt(ID, offset__tmp, t__tmp)\
  ret.is_null = offset__tmp == 0; ret.value = offset__tmp ?\
  __flatbuffers_read_scalar_at_byteoffset(TK, t__tmp, offset__tmp) : V;\
  return ret; }
#define __flatbuffers_struct_field(T, ID, t, r)\
{\
    __flatbuffers_read_vt(ID, offset__tmp, t)\
    if (offset__tmp) {\
        return (T)((uint8_t *)(t) + offset__tmp);\
    }\
    FLATCC_ASSERT(!(r) && "required field missing");\
    return 0;\
}
#define __flatbuffers_offset_field(T, ID, t, r, adjust)\
{\
    flatbuffers_uoffset_t *elem__tmp;\
    __flatbuffers_read_vt(ID, offset__tmp, t)\
    if (offset__tmp) {\
        elem__tmp = (flatbuffers_uoffset_t *)((uint8_t *)(t) + offset__tmp);\
        /* Add sizeof so C api can have raw access past header field. */\
        return (T)((uint8_t *)(elem__tmp) + adjust +\
              __flatbuffers_uoffset_read_from_pe(elem__tmp));\
    }\
    FLATCC_ASSERT(!(r) && "required field missing");\
    return 0;\
}
#define __flatbuffers_vector_field(T, ID, t, r) __flatbuffers_offset_field(T, ID, t, r, sizeof(flatbuffers_uoffset_t))
#define __flatbuffers_table_field(T, ID, t, r) __flatbuffers_offset_field(T, ID, t, r, 0)
#define __flatbuffers_define_struct_field(ID, N, NK, T, r)\
static inline T N ## _ ## NK ## _get(N ## _table_t t__tmp)\
__flatbuffers_struct_field(T, ID, t__tmp, r)\
static inline T N ## _ ## NK(N ## _table_t t__tmp)\
__flatbuffers_struct_field(T, ID, t__tmp, r)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__flatbuffers_field_present(ID, t__tmp)
#define __flatbuffers_define_vector_field(ID, N, NK, T, r)\
static inline T N ## _ ## NK ## _get(N ## _table_t t__tmp)\
__flatbuffers_vector_field(T, ID, t__tmp, r)\
static inline T N ## _ ## NK(N ## _table_t t__tmp)\
__flatbuffers_vector_field(T, ID, t__tmp, r)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__flatbuffers_field_present(ID, t__tmp)
#define __flatbuffers_define_table_field(ID, N, NK, T, r)\
static inline T N ## _ ## NK ## _get(N ## _table_t t__tmp)\
__flatbuffers_table_field(T, ID, t__tmp, r)\
static inline T N ## _ ## NK(N ## _table_t t__tmp)\
__flatbuffers_table_field(T, ID, t__tmp, r)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__flatbuffers_field_present(ID, t__tmp)
#define __flatbuffers_define_string_field(ID, N, NK, r)\
static inline flatbuffers_string_t N ## _ ## NK ## _get(N ## _table_t t__tmp)\
__flatbuffers_vector_field(flatbuffers_string_t, ID, t__tmp, r)\
static inline flatbuffers_string_t N ## _ ## NK(N ## _table_t t__tmp)\
__flatbuffers_vector_field(flatbuffers_string_t, ID, t__tmp, r)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__flatbuffers_field_present(ID, t__tmp)\
__flatbuffers_define_scan_by_string_field(N, NK)
#define __flatbuffers_vec_len(vec)\
{ return (vec) ? (size_t)__flatbuffers_uoffset_read_from_pe((flatbuffers_uoffset_t *)vec - 1) : 0; }
#define __flatbuffers_string_len(s) __flatbuffers_vec_len(s)
static inline size_t flatbuffers_vec_len(const void *vec)
__flatbuffers_vec_len(vec)
#define __flatbuffers_scalar_vec_at(N, vec, i)\
{ FLATCC_ASSERT(flatbuffers_vec_len(vec) > (i) && "index out of range");\
  return __flatbuffers_read_scalar(N, &(vec)[i]); }
#define __flatbuffers_struct_vec_at(vec, i)\
{ FLATCC_ASSERT(flatbuffers_vec_len(vec) > (i) && "index out of range"); return (vec) + (i); }
/* `adjust` skips past the header for string vectors. */
#define __flatbuffers_offset_vec_at(T, vec, i, adjust)\
{ const flatbuffers_uoffset_t *elem__tmp = (vec) + (i);\
  FLATCC_ASSERT(flatbuffers_vec_len(vec) > (i) && "index out of range");\
  return (T)((uint8_t *)(elem__tmp) + (size_t)__flatbuffers_uoffset_read_from_pe(elem__tmp) + (adjust)); }
#define __flatbuffers_define_scalar_vec_len(N)\
static inline size_t N ## _vec_len(N ##_vec_t vec__tmp)\
{ return flatbuffers_vec_len(vec__tmp); }
#define __flatbuffers_define_scalar_vec_at(N, T) \
static inline T N ## _vec_at(N ## _vec_t vec__tmp, size_t i__tmp)\
__flatbuffers_scalar_vec_at(N, vec__tmp, i__tmp)
typedef const char *flatbuffers_string_t;
static inline size_t flatbuffers_string_len(flatbuffers_string_t s)
__flatbuffers_string_len(s)
typedef const flatbuffers_uoffset_t *flatbuffers_string_vec_t;
typedef flatbuffers_uoffset_t *flatbuffers_string_mutable_vec_t;
static inline size_t flatbuffers_string_vec_len(flatbuffers_string_vec_t vec)
__flatbuffers_vec_len(vec)
static inline flatbuffers_string_t flatbuffers_string_vec_at(flatbuffers_string_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(flatbuffers_string_t, vec, i, sizeof(vec[0]))
typedef const void *flatbuffers_generic_t;
typedef void *flatbuffers_mutable_generic_t;
static inline flatbuffers_string_t flatbuffers_string_cast_from_generic(const flatbuffers_generic_t p)
{ return p ? ((const char *)p) + __flatbuffers_uoffset__size() : 0; }
typedef const flatbuffers_uoffset_t *flatbuffers_generic_vec_t;
typedef flatbuffers_uoffset_t *flatbuffers_generic_table_mutable_vec_t;
static inline size_t flatbuffers_generic_vec_len(flatbuffers_generic_vec_t vec)
__flatbuffers_vec_len(vec)
static inline flatbuffers_generic_t flatbuffers_generic_vec_at(flatbuffers_generic_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(flatbuffers_generic_t, vec, i, 0)
static inline flatbuffers_generic_t flatbuffers_generic_vec_at_as_string(flatbuffers_generic_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(flatbuffers_generic_t, vec, i, sizeof(vec[0]))
typedef struct flatbuffers_union {
    flatbuffers_union_type_t type;
    flatbuffers_generic_t value;
} flatbuffers_union_t;
typedef struct flatbuffers_union_vec {
    const flatbuffers_union_type_t *type;
    const flatbuffers_uoffset_t *value;
} flatbuffers_union_vec_t;
typedef struct flatbuffers_mutable_union {
    flatbuffers_union_type_t type;
    flatbuffers_mutable_generic_t value;
} flatbuffers_mutable_union_t;
typedef struct flatbuffers_mutable_union_vec {
    flatbuffers_union_type_t *type;
    flatbuffers_uoffset_t *value;
} flatbuffers_mutable_union_vec_t;
static inline flatbuffers_mutable_union_t flatbuffers_mutable_union_cast(flatbuffers_union_t u__tmp)\
{ flatbuffers_mutable_union_t mu = { u__tmp.type, (flatbuffers_mutable_generic_t)u__tmp.value };\
  return mu; }
static inline flatbuffers_mutable_union_vec_t flatbuffers_mutable_union_vec_cast(flatbuffers_union_vec_t uv__tmp)\
{ flatbuffers_mutable_union_vec_t muv =\
  { (flatbuffers_union_type_t *)uv__tmp.type, (flatbuffers_uoffset_t *)uv__tmp.value }; return muv; }
#define __flatbuffers_union_type_field(ID, t)\
{\
    __flatbuffers_read_vt(ID, offset__tmp, t)\
    return offset__tmp ? __flatbuffers_read_scalar_at_byteoffset(__flatbuffers_utype, t, offset__tmp) : 0;\
}
static inline flatbuffers_string_t flatbuffers_string_cast_from_union(const flatbuffers_union_t u__tmp)\
{ return flatbuffers_string_cast_from_generic(u__tmp.value); }
#define __flatbuffers_define_union_field(NS, ID, N, NK, T, r)\
static inline T ## _union_type_t N ## _ ## NK ## _type_get(N ## _table_t t__tmp)\
__## NS ## union_type_field(((ID) - 1), t__tmp)\
static inline NS ## generic_t N ## _ ## NK ## _get(N ## _table_t t__tmp)\
__## NS ## table_field(NS ## generic_t, ID, t__tmp, r)\
static inline T ## _union_type_t N ## _ ## NK ## _type(N ## _table_t t__tmp)\
__## NS ## union_type_field(((ID) - 1), t__tmp)\
static inline NS ## generic_t N ## _ ## NK(N ## _table_t t__tmp)\
__## NS ## table_field(NS ## generic_t, ID, t__tmp, r)\
static inline int N ## _ ## NK ## _is_present(N ## _table_t t__tmp)\
__## NS ## field_present(ID, t__tmp)\
static inline T ## _union_t N ## _ ## NK ## _union(N ## _table_t t__tmp)\
{ T ## _union_t u__tmp = { 0, 0 }; u__tmp.type = N ## _ ## NK ## _type_get(t__tmp);\
  if (u__tmp.type == 0) return u__tmp; u__tmp.value = N ## _ ## NK ## _get(t__tmp); return u__tmp; }\
static inline NS ## string_t N ## _ ## NK ## _as_string(N ## _table_t t__tmp)\
{ return NS ## string_cast_from_generic(N ## _ ## NK ## _get(t__tmp)); }\

#define __flatbuffers_define_union_vector_ops(NS, T)\
static inline size_t T ## _union_vec_len(T ## _union_vec_t uv__tmp)\
{ return NS ## vec_len(uv__tmp.type); }\
static inline T ## _union_t T ## _union_vec_at(T ## _union_vec_t uv__tmp, size_t i__tmp)\
{ T ## _union_t u__tmp = { 0, 0 }; size_t n__tmp = NS ## vec_len(uv__tmp.type);\
  FLATCC_ASSERT(n__tmp > (i__tmp) && "index out of range"); u__tmp.type = uv__tmp.type[i__tmp];\
  /* Unknown type is treated as NONE for schema evolution. */\
  if (u__tmp.type == 0) return u__tmp;\
  u__tmp.value = NS ## generic_vec_at(uv__tmp.value, i__tmp); return u__tmp; }\
static inline NS ## string_t T ## _union_vec_at_as_string(T ## _union_vec_t uv__tmp, size_t i__tmp)\
{ return (NS ## string_t) NS ## generic_vec_at_as_string(uv__tmp.value, i__tmp); }\

#define __flatbuffers_define_union_vector(NS, T)\
typedef NS ## union_vec_t T ## _union_vec_t;\
typedef NS ## mutable_union_vec_t T ## _mutable_union_vec_t;\
static inline T ## _mutable_union_vec_t T ## _mutable_union_vec_cast(T ## _union_vec_t u__tmp)\
{ return NS ## mutable_union_vec_cast(u__tmp); }\
__## NS ## define_union_vector_ops(NS, T)
#define __flatbuffers_define_union(NS, T)\
typedef NS ## union_t T ## _union_t;\
typedef NS ## mutable_union_t T ## _mutable_union_t;\
static inline T ## _mutable_union_t T ## _mutable_union_cast(T ## _union_t u__tmp)\
{ return NS ## mutable_union_cast(u__tmp); }\
__## NS ## define_union_vector(NS, T)
#define __flatbuffers_define_union_vector_field(NS, ID, N, NK, T, r)\
__## NS ## define_vector_field(ID - 1, N, NK ## _type, T ## _vec_t, r)\
__## NS ## define_vector_field(ID, N, NK, flatbuffers_generic_vec_t, r)\
static inline T ## _union_vec_t N ## _ ## NK ## _union(N ## _table_t t__tmp)\
{ T ## _union_vec_t uv__tmp; uv__tmp.type = N ## _ ## NK ## _type_get(t__tmp);\
  uv__tmp.value = N ## _ ## NK(t__tmp);\
  FLATCC_ASSERT(NS ## vec_len(uv__tmp.type) == NS ## vec_len(uv__tmp.value)\
  && "union vector type length mismatch"); return uv__tmp; }
#include <string.h>
static const size_t flatbuffers_not_found = (size_t)-1;
static const size_t flatbuffers_end = (size_t)-1;
#define __flatbuffers_identity(n) (n)
#define __flatbuffers_min(a, b) ((a) < (b) ? (a) : (b))
/* Subtraction doesn't work for unsigned types. */
#define __flatbuffers_scalar_cmp(x, y, n) ((x) < (y) ? -1 : (x) > (y))
static inline int __flatbuffers_string_n_cmp(flatbuffers_string_t v, const char *s, size_t n)
{ size_t nv = flatbuffers_string_len(v); int x = strncmp(v, s, nv < n ? nv : n);
  return x != 0 ? x : nv < n ? -1 : nv > n; }
/* `n` arg unused, but needed by string find macro expansion. */
static inline int __flatbuffers_string_cmp(flatbuffers_string_t v, const char *s, size_t n) { (void)n; return strcmp(v, s); }
/* A = identity if searching scalar vectors rather than key fields. */
/* Returns lowest matching index or not_found. */
#define __flatbuffers_find_by_field(A, V, E, L, K, Kn, T, D)\
{ T v__tmp; size_t a__tmp = 0, b__tmp, m__tmp; if (!(b__tmp = L(V))) { return flatbuffers_not_found; }\
  --b__tmp;\
  while (a__tmp < b__tmp) {\
    m__tmp = a__tmp + ((b__tmp - a__tmp) >> 1);\
    v__tmp = A(E(V, m__tmp));\
    if ((D(v__tmp, (K), (Kn))) < 0) {\
      a__tmp = m__tmp + 1;\
    } else {\
      b__tmp = m__tmp;\
    }\
  }\
  if (a__tmp == b__tmp) {\
    v__tmp = A(E(V, a__tmp));\
    if (D(v__tmp, (K), (Kn)) == 0) {\
       return a__tmp;\
    }\
  }\
  return flatbuffers_not_found;\
}
#define __flatbuffers_find_by_scalar_field(A, V, E, L, K, T)\
__flatbuffers_find_by_field(A, V, E, L, K, 0, T, __flatbuffers_scalar_cmp)
#define __flatbuffers_find_by_string_field(A, V, E, L, K)\
__flatbuffers_find_by_field(A, V, E, L, K, 0, flatbuffers_string_t, __flatbuffers_string_cmp)
#define __flatbuffers_find_by_string_n_field(A, V, E, L, K, Kn)\
__flatbuffers_find_by_field(A, V, E, L, K, Kn, flatbuffers_string_t, __flatbuffers_string_n_cmp)
#define __flatbuffers_define_find_by_scalar_field(N, NK, TK)\
static inline size_t N ## _vec_find_by_ ## NK(N ## _vec_t vec__tmp, TK key__tmp)\
__flatbuffers_find_by_scalar_field(N ## _ ## NK, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, TK)
#define __flatbuffers_define_scalar_find(N, T)\
static inline size_t N ## _vec_find(N ## _vec_t vec__tmp, T key__tmp)\
__flatbuffers_find_by_scalar_field(__flatbuffers_identity, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)
#define __flatbuffers_define_find_by_string_field(N, NK) \
/* Note: find only works on vectors sorted by this field. */\
static inline size_t N ## _vec_find_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp)\
__flatbuffers_find_by_string_field(N ## _ ## NK, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp)\
static inline size_t N ## _vec_find_n_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
__flatbuffers_find_by_string_n_field(N ## _ ## NK, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp, n__tmp)
#define __flatbuffers_define_default_find_by_scalar_field(N, NK, TK)\
static inline size_t N ## _vec_find(N ## _vec_t vec__tmp, TK key__tmp)\
{ return N ## _vec_find_by_ ## NK(vec__tmp, key__tmp); }
#define __flatbuffers_define_default_find_by_string_field(N, NK) \
static inline size_t N ## _vec_find(N ## _vec_t vec__tmp, const char *s__tmp)\
{ return N ## _vec_find_by_ ## NK(vec__tmp, s__tmp); }\
static inline size_t N ## _vec_find_n(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
{ return N ## _vec_find_n_by_ ## NK(vec__tmp, s__tmp, n__tmp); }
/* A = identity if searching scalar vectors rather than key fields. */
/* Returns lowest matching index or not_found. */
#define __flatbuffers_scan_by_field(b, e, A, V, E, L, K, Kn, T, D)\
{ T v__tmp; size_t i__tmp;\
  for (i__tmp = b; i__tmp < e; ++i__tmp) {\
    v__tmp = A(E(V, i__tmp));\
    if (D(v__tmp, (K), (Kn)) == 0) {\
       return i__tmp;\
    }\
  }\
  return flatbuffers_not_found;\
}
#define __flatbuffers_rscan_by_field(b, e, A, V, E, L, K, Kn, T, D)\
{ T v__tmp; size_t i__tmp = e;\
  while (i__tmp-- > b) {\
    v__tmp = A(E(V, i__tmp));\
    if (D(v__tmp, (K), (Kn)) == 0) {\
       return i__tmp;\
    }\
  }\
  return flatbuffers_not_found;\
}
#define __flatbuffers_scan_by_scalar_field(b, e, A, V, E, L, K, T)\
__flatbuffers_scan_by_field(b, e, A, V, E, L, K, 0, T, __flatbuffers_scalar_cmp)
#define __flatbuffers_scan_by_string_field(b, e, A, V, E, L, K)\
__flatbuffers_scan_by_field(b, e, A, V, E, L, K, 0, flatbuffers_string_t, __flatbuffers_string_cmp)
#define __flatbuffers_scan_by_string_n_field(b, e, A, V, E, L, K, Kn)\
__flatbuffers_scan_by_field(b, e, A, V, E, L, K, Kn, flatbuffers_string_t, __flatbuffers_string_n_cmp)
#define __flatbuffers_rscan_by_scalar_field(b, e, A, V, E, L, K, T)\
__flatbuffers_rscan_by_field(b, e, A, V, E, L, K, 0, T, __flatbuffers_scalar_cmp)
#define __flatbuffers_rscan_by_string_field(b, e, A, V, E, L, K)\
__flatbuffers_rscan_by_field(b, e, A, V, E, L, K, 0, flatbuffers_string_t, __flatbuffers_string_cmp)
#define __flatbuffers_rscan_by_string_n_field(b, e, A, V, E, L, K, Kn)\
__flatbuffers_rscan_by_field(b, e, A, V, E, L, K, Kn, flatbuffers_string_t, __flatbuffers_string_n_cmp)
#define __flatbuffers_define_scan_by_scalar_field(N, NK, T)\
static inline size_t N ## _vec_scan_by_ ## NK(N ## _vec_t vec__tmp, T key__tmp)\
__flatbuffers_scan_by_scalar_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_scan_ex_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, T key__tmp)\
__flatbuffers_scan_by_scalar_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_rscan_by_ ## NK(N ## _vec_t vec__tmp, T key__tmp)\
__flatbuffers_rscan_by_scalar_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_rscan_ex_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, T key__tmp)\
__flatbuffers_rscan_by_scalar_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)
#define __flatbuffers_define_scalar_scan(N, T)\
static inline size_t N ## _vec_scan(N ## _vec_t vec__tmp, T key__tmp)\
__flatbuffers_scan_by_scalar_field(0, N ## _vec_len(vec__tmp), __flatbuffers_identity, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_scan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, T key__tmp)\
__flatbuffers_scan_by_scalar_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), __flatbuffers_identity, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_rscan(N ## _vec_t vec__tmp, T key__tmp)\
__flatbuffers_rscan_by_scalar_field(0, N ## _vec_len(vec__tmp), __flatbuffers_identity, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)\
static inline size_t N ## _vec_rscan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, T key__tmp)\
__flatbuffers_rscan_by_scalar_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), __flatbuffers_identity, vec__tmp, N ## _vec_at, N ## _vec_len, key__tmp, T)
#define __flatbuffers_define_scan_by_string_field(N, NK) \
static inline size_t N ## _vec_scan_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp)\
__flatbuffers_scan_by_string_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp)\
static inline size_t N ## _vec_scan_n_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
__flatbuffers_scan_by_string_n_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp, n__tmp)\
static inline size_t N ## _vec_scan_ex_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp)\
__flatbuffers_scan_by_string_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp)\
static inline size_t N ## _vec_scan_ex_n_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp, size_t n__tmp)\
__flatbuffers_scan_by_string_n_field(begin__tmp, __flatbuffers_min( end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp, n__tmp)\
static inline size_t N ## _vec_rscan_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp)\
__flatbuffers_rscan_by_string_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp)\
static inline size_t N ## _vec_rscan_n_by_ ## NK(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
__flatbuffers_rscan_by_string_n_field(0, N ## _vec_len(vec__tmp), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp, n__tmp)\
static inline size_t N ## _vec_rscan_ex_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp)\
__flatbuffers_rscan_by_string_field(begin__tmp, __flatbuffers_min(end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp)\
static inline size_t N ## _vec_rscan_ex_n_by_ ## NK(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp, size_t n__tmp)\
__flatbuffers_rscan_by_string_n_field(begin__tmp, __flatbuffers_min( end__tmp, N ## _vec_len(vec__tmp)), N ## _ ## NK ## _get, vec__tmp, N ## _vec_at, N ## _vec_len, s__tmp, n__tmp)
#define __flatbuffers_define_default_scan_by_scalar_field(N, NK, TK)\
static inline size_t N ## _vec_scan(N ## _vec_t vec__tmp, TK key__tmp)\
{ return N ## _vec_scan_by_ ## NK(vec__tmp, key__tmp); }\
static inline size_t N ## _vec_scan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, TK key__tmp)\
{ return N ## _vec_scan_ex_by_ ## NK(vec__tmp, begin__tmp, end__tmp, key__tmp); }\
static inline size_t N ## _vec_rscan(N ## _vec_t vec__tmp, TK key__tmp)\
{ return N ## _vec_rscan_by_ ## NK(vec__tmp, key__tmp); }\
static inline size_t N ## _vec_rscan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, TK key__tmp)\
{ return N ## _vec_rscan_ex_by_ ## NK(vec__tmp, begin__tmp, end__tmp, key__tmp); }
#define __flatbuffers_define_default_scan_by_string_field(N, NK) \
static inline size_t N ## _vec_scan(N ## _vec_t vec__tmp, const char *s__tmp)\
{ return N ## _vec_scan_by_ ## NK(vec__tmp, s__tmp); }\
static inline size_t N ## _vec_scan_n(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
{ return N ## _vec_scan_n_by_ ## NK(vec__tmp, s__tmp, n__tmp); }\
static inline size_t N ## _vec_scan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp)\
{ return N ## _vec_scan_ex_by_ ## NK(vec__tmp, begin__tmp, end__tmp, s__tmp); }\
static inline size_t N ## _vec_scan_ex_n(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp, size_t n__tmp)\
{ return N ## _vec_scan_ex_n_by_ ## NK(vec__tmp, begin__tmp, end__tmp, s__tmp, n__tmp); }\
static inline size_t N ## _vec_rscan(N ## _vec_t vec__tmp, const char *s__tmp)\
{ return N ## _vec_rscan_by_ ## NK(vec__tmp, s__tmp); }\
static inline size_t N ## _vec_rscan_n(N ## _vec_t vec__tmp, const char *s__tmp, size_t n__tmp)\
{ return N ## _vec_rscan_n_by_ ## NK(vec__tmp, s__tmp, n__tmp); }\
static inline size_t N ## _vec_rscan_ex(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp)\
{ return N ## _vec_rscan_ex_by_ ## NK(vec__tmp, begin__tmp, end__tmp, s__tmp); }\
static inline size_t N ## _vec_rscan_ex_n(N ## _vec_t vec__tmp, size_t begin__tmp, size_t end__tmp, const char *s__tmp, size_t n__tmp)\
{ return N ## _vec_rscan_ex_n_by_ ## NK(vec__tmp, begin__tmp, end__tmp, s__tmp, n__tmp); }
#define __flatbuffers_heap_sort(N, X, A, E, L, TK, TE, D, S)\
static inline void __ ## N ## X ## __heap_sift_down(\
        N ## _mutable_vec_t vec__tmp, size_t start__tmp, size_t end__tmp)\
{ size_t child__tmp, root__tmp; TK v1__tmp, v2__tmp, vroot__tmp;\
  root__tmp = start__tmp;\
  while ((root__tmp << 1) <= end__tmp) {\
    child__tmp = root__tmp << 1;\
    if (child__tmp < end__tmp) {\
      v1__tmp = A(E(vec__tmp, child__tmp));\
      v2__tmp = A(E(vec__tmp, child__tmp + 1));\
      if (D(v1__tmp, v2__tmp) < 0) {\
        child__tmp++;\
      }\
    }\
    vroot__tmp = A(E(vec__tmp, root__tmp));\
    v1__tmp = A(E(vec__tmp, child__tmp));\
    if (D(vroot__tmp, v1__tmp) < 0) {\
      S(vec__tmp, root__tmp, child__tmp, TE);\
      root__tmp = child__tmp;\
    } else {\
      return;\
    }\
  }\
}\
static inline void __ ## N ## X ## __heap_sort(N ## _mutable_vec_t vec__tmp)\
{ size_t start__tmp, end__tmp, size__tmp;\
  size__tmp = L(vec__tmp); if (size__tmp == 0) return; end__tmp = size__tmp - 1; start__tmp = size__tmp >> 1;\
  do { __ ## N ## X ## __heap_sift_down(vec__tmp, start__tmp, end__tmp); } while (start__tmp--);\
  while (end__tmp > 0) { \
    S(vec__tmp, 0, end__tmp, TE);\
    __ ## N ## X ## __heap_sift_down(vec__tmp, 0, --end__tmp); } }
#define __flatbuffers_define_sort_by_field(N, NK, TK, TE, D, S)\
  __flatbuffers_heap_sort(N, _sort_by_ ## NK, N ## _ ## NK ## _get, N ## _vec_at, N ## _vec_len, TK, TE, D, S)\
static inline void N ## _vec_sort_by_ ## NK(N ## _mutable_vec_t vec__tmp)\
{ __ ## N ## _sort_by_ ## NK ## __heap_sort(vec__tmp); }
#define __flatbuffers_define_sort(N, TK, TE, D, S)\
__flatbuffers_heap_sort(N, , __flatbuffers_identity, N ## _vec_at, N ## _vec_len, TK, TE, D, S)\
static inline void N ## _vec_sort(N ## _mutable_vec_t vec__tmp) { __ ## N ## __heap_sort(vec__tmp); }
#define __flatbuffers_scalar_diff(x, y) ((x) < (y) ? -1 : (x) > (y))
#define __flatbuffers_string_diff(x, y) __flatbuffers_string_n_cmp((x), (const char *)(y), flatbuffers_string_len(y))
#define __flatbuffers_value_swap(vec, a, b, TE) { TE x__tmp = vec[b]; vec[b] = vec[a]; vec[a] = x__tmp; }
#define __flatbuffers_uoffset_swap(vec, a, b, TE)\
{ TE ta__tmp, tb__tmp, d__tmp;\
  d__tmp = (TE)((a - b) * sizeof(vec[0]));\
  ta__tmp =  __flatbuffers_uoffset_read_from_pe(vec + b) - d__tmp;\
  tb__tmp =  __flatbuffers_uoffset_read_from_pe(vec + a) + d__tmp;\
  __flatbuffers_uoffset_write_to_pe(vec + a, ta__tmp);\
  __flatbuffers_uoffset_write_to_pe(vec + b, tb__tmp); }
#define __flatbuffers_scalar_swap(vec, a, b, TE) __flatbuffers_value_swap(vec, a, b, TE)
#define __flatbuffers_string_swap(vec, a, b, TE) __flatbuffers_uoffset_swap(vec, a, b, TE)
#define __flatbuffers_struct_swap(vec, a, b, TE) __flatbuffers_value_swap(vec, a, b, TE)
#define __flatbuffers_table_swap(vec, a, b, TE) __flatbuffers_uoffset_swap(vec, a, b, TE)
#define __flatbuffers_define_struct_sort_by_scalar_field(N, NK, TK, TE)\
  __flatbuffers_define_sort_by_field(N, NK, TK, TE, __flatbuffers_scalar_diff, __flatbuffers_struct_swap)
#define __flatbuffers_define_table_sort_by_scalar_field(N, NK, TK)\
  __flatbuffers_define_sort_by_field(N, NK, TK, flatbuffers_uoffset_t, __flatbuffers_scalar_diff, __flatbuffers_table_swap)
#define __flatbuffers_define_table_sort_by_string_field(N, NK)\
  __flatbuffers_define_sort_by_field(N, NK, flatbuffers_string_t, flatbuffers_uoffset_t, __flatbuffers_string_diff, __flatbuffers_table_swap)
#define __flatbuffers_define_scalar_sort(N, T) __flatbuffers_define_sort(N, T, T, __flatbuffers_scalar_diff, __flatbuffers_scalar_swap)
#define __flatbuffers_define_string_sort() __flatbuffers_define_sort(flatbuffers_string, flatbuffers_string_t, flatbuffers_uoffset_t, __flatbuffers_string_diff, __flatbuffers_string_swap)
#define __flatbuffers_sort_vector_field(N, NK, T, t)\
{ T ## _mutable_vec_t v__tmp = (T ## _mutable_vec_t) N ## _ ## NK ## _get(t);\
  if (v__tmp) T ## _vec_sort(v__tmp); }
#define __flatbuffers_sort_table_field(N, NK, T, t)\
{ T ## _sort((T ## _mutable_table_t)N ## _ ## NK ## _get(t)); }
#define __flatbuffers_sort_union_field(N, NK, T, t)\
{ T ## _sort(T ## _mutable_union_cast(N ## _ ## NK ## _union(t))); }
#define __flatbuffers_sort_table_vector_field_elements(N, NK, T, t)\
{ T ## _vec_t v__tmp = N ## _ ## NK ## _get(t); size_t i__tmp, n__tmp;\
  n__tmp = T ## _vec_len(v__tmp); for (i__tmp = 0; i__tmp < n__tmp; ++i__tmp) {\
  T ## _sort((T ## _mutable_table_t)T ## _vec_at(v__tmp, i__tmp)); }}
#define __flatbuffers_sort_union_vector_field_elements(N, NK, T, t)\
{ T ## _union_vec_t v__tmp = N ## _ ## NK ## _union(t); size_t i__tmp, n__tmp;\
  n__tmp = T ## _union_vec_len(v__tmp); for (i__tmp = 0; i__tmp < n__tmp; ++i__tmp) {\
  T ## _sort(T ## _mutable_union_cast(T ## _union_vec_at(v__tmp, i__tmp))); }}
#define __flatbuffers_define_scalar_vector(N, T)\
typedef const T *N ## _vec_t;\
typedef T *N ## _mutable_vec_t;\
__flatbuffers_define_scalar_vec_len(N)\
__flatbuffers_define_scalar_vec_at(N, T)\
__flatbuffers_define_scalar_find(N, T)\
__flatbuffers_define_scalar_scan(N, T)\
__flatbuffers_define_scalar_sort(N, T)

#define __flatbuffers_define_integer_type(N, T, W)\
__flatcc_define_integer_accessors(N, T, W, flatbuffers_endian)\
__flatbuffers_define_scalar_vector(N, T)
__flatbuffers_define_scalar_vector(flatbuffers_bool, flatbuffers_bool_t)
__flatbuffers_define_scalar_vector(flatbuffers_char, char)
__flatbuffers_define_scalar_vector(flatbuffers_uint8, uint8_t)
__flatbuffers_define_scalar_vector(flatbuffers_int8, int8_t)
__flatbuffers_define_scalar_vector(flatbuffers_uint16, uint16_t)
__flatbuffers_define_scalar_vector(flatbuffers_int16, int16_t)
__flatbuffers_define_scalar_vector(flatbuffers_uint32, uint32_t)
__flatbuffers_define_scalar_vector(flatbuffers_int32, int32_t)
__flatbuffers_define_scalar_vector(flatbuffers_uint64, uint64_t)
__flatbuffers_define_scalar_vector(flatbuffers_int64, int64_t)
__flatbuffers_define_scalar_vector(flatbuffers_float, float)
__flatbuffers_define_scalar_vector(flatbuffers_double, double)
__flatbuffers_define_scalar_vector(flatbuffers_union_type, flatbuffers_union_type_t)
static inline size_t flatbuffers_string_vec_find(flatbuffers_string_vec_t vec, const char *s)
__flatbuffers_find_by_string_field(__flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s)
static inline size_t flatbuffers_string_vec_find_n(flatbuffers_string_vec_t vec, const char *s, size_t n)
__flatbuffers_find_by_string_n_field(__flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s, n)
static inline size_t flatbuffers_string_vec_scan(flatbuffers_string_vec_t vec, const char *s)
__flatbuffers_scan_by_string_field(0, flatbuffers_string_vec_len(vec), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s)
static inline size_t flatbuffers_string_vec_scan_n(flatbuffers_string_vec_t vec, const char *s, size_t n)
__flatbuffers_scan_by_string_n_field(0, flatbuffers_string_vec_len(vec), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s, n)
static inline size_t flatbuffers_string_vec_scan_ex(flatbuffers_string_vec_t vec, size_t begin, size_t end, const char *s)
__flatbuffers_scan_by_string_field(begin, __flatbuffers_min(end, flatbuffers_string_vec_len(vec)), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s)
static inline size_t flatbuffers_string_vec_scan_ex_n(flatbuffers_string_vec_t vec, size_t begin, size_t end, const char *s, size_t n)
__flatbuffers_scan_by_string_n_field(begin, __flatbuffers_min(end, flatbuffers_string_vec_len(vec)), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s, n)
static inline size_t flatbuffers_string_vec_rscan(flatbuffers_string_vec_t vec, const char *s)
__flatbuffers_rscan_by_string_field(0, flatbuffers_string_vec_len(vec), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s)
static inline size_t flatbuffers_string_vec_rscan_n(flatbuffers_string_vec_t vec, const char *s, size_t n)
__flatbuffers_rscan_by_string_n_field(0, flatbuffers_string_vec_len(vec), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s, n)
static inline size_t flatbuffers_string_vec_rscan_ex(flatbuffers_string_vec_t vec, size_t begin, size_t end, const char *s)
__flatbuffers_rscan_by_string_field(begin, __flatbuffers_min(end, flatbuffers_string_vec_len(vec)), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s)
static inline size_t flatbuffers_string_vec_rscan_ex_n(flatbuffers_string_vec_t vec, size_t begin, size_t end, const char *s, size_t n)
__flatbuffers_rscan_by_string_n_field(begin, __flatbuffers_min(end, flatbuffers_string_vec_len(vec)), __flatbuffers_identity, vec, flatbuffers_string_vec_at, flatbuffers_string_vec_len, s, n)
__flatbuffers_define_string_sort()
#define __flatbuffers_define_struct_scalar_fixed_array_field(N, NK, TK, T, L)\
static inline T N ## _ ## NK ## _get(N ## _struct_t t__tmp, size_t i__tmp)\
{ if (!t__tmp || i__tmp >= L) return 0;\
  return __flatbuffers_read_scalar(TK, &(t__tmp->NK[i__tmp])); }\
static inline const T *N ## _ ## NK ## _get_ptr(N ## _struct_t t__tmp)\
{ return t__tmp ? t__tmp->NK : 0; }\
static inline size_t N ## _ ## NK ## _get_len(void) { return L; }\
static inline T N ## _ ## NK (N ## _struct_t t__tmp, size_t i__tmp)\
{ return N ## _ ## NK ## _get(t__tmp, i__tmp); }
#define __flatbuffers_define_struct_struct_fixed_array_field(N, NK, T, L)\
static inline T N ## _ ## NK ## _get(N ## _struct_t t__tmp, size_t i__tmp)\
{ if (!t__tmp || i__tmp >= L) return 0; return t__tmp->NK + i__tmp; }static inline T N ## _ ## NK ## _get_ptr(N ## _struct_t t__tmp)\
{ return t__tmp ? t__tmp->NK : 0; }\
static inline size_t N ## _ ## NK ## _get_len(void) { return L; }\
static inline T N ## _ ## NK(N ## _struct_t t__tmp, size_t i__tmp)\
{ if (!t__tmp || i__tmp >= L) return 0; return t__tmp->NK + i__tmp; }
#define __flatbuffers_define_struct_scalar_field(N, NK, TK, T)\
static inline T N ## _ ## NK ## _get(N ## _struct_t t__tmp)\
{ return t__tmp ? __flatbuffers_read_scalar(TK, &(t__tmp->NK)) : 0; }\
static inline const T *N ## _ ## NK ## _get_ptr(N ## _struct_t t__tmp)\
{ return t__tmp ? &(t__tmp->NK) : 0; }\
static inline T N ## _ ## NK (N ## _struct_t t__tmp)\
{ return t__tmp ? __flatbuffers_read_scalar(TK, &(t__tmp->NK)) : 0; }\
__flatbuffers_define_scan_by_scalar_field(N, NK, T)
#define __flatbuffers_define_struct_struct_field(N, NK, T)\
static inline T N ## _ ## NK ## _get(N ## _struct_t t__tmp) { return t__tmp ? &(t__tmp->NK) : 0; }\
static inline T N ## _ ## NK (N ## _struct_t t__tmp) { return t__tmp ? &(t__tmp->NK) : 0; }
/* If fid is null, the function returns true without testing as buffer is not expected to have any id. */
static inline int flatbuffers_has_identifier(const void *buffer, const char *fid)
{ flatbuffers_thash_t id, id2 = 0; if (fid == 0) { return 1; };
  id2 = flatbuffers_type_hash_from_string(fid);
  id = __flatbuffers_thash_read_from_pe(((flatbuffers_uoffset_t *)buffer) + 1);
  return id2 == 0 || id == id2; }
static inline int flatbuffers_has_type_hash(const void *buffer, flatbuffers_thash_t thash)
{ return thash == 0 || (__flatbuffers_thash_read_from_pe((flatbuffers_uoffset_t *)buffer + 1) == thash); }

static inline flatbuffers_thash_t flatbuffers_get_type_hash(const void *buffer)
{ return __flatbuffers_thash_read_from_pe((flatbuffers_uoffset_t *)buffer + 1); }

#define flatbuffers_verify_endian() flatbuffers_has_identifier("\x00\x00\x00\x00" "1234", "1234")
static inline void *flatbuffers_read_size_prefix(void *b, size_t *size_out)
{ if (size_out) { *size_out = (size_t)__flatbuffers_uoffset_read_from_pe(b); }
  return (uint8_t *)b + sizeof(flatbuffers_uoffset_t); }
/* Null file identifier accepts anything, otherwise fid should be 4 characters. */
#define __flatbuffers_read_root(T, K, buffer, fid)\
  ((!buffer || !flatbuffers_has_identifier(buffer, fid)) ? 0 :\
  ((T ## _ ## K ## t)(((uint8_t *)buffer) +\
    __flatbuffers_uoffset_read_from_pe(buffer))))
#define __flatbuffers_read_typed_root(T, K, buffer, thash)\
  ((!buffer || !flatbuffers_has_type_hash(buffer, thash)) ? 0 :\
  ((T ## _ ## K ## t)(((uint8_t *)buffer) +\
    __flatbuffers_uoffset_read_from_pe(buffer))))
#define __flatbuffers_nested_buffer_as_root(C, N, T, K)\
static inline T ## _ ## K ## t C ## _ ## N ## _as_root_with_identifier(C ## _ ## table_t t__tmp, const char *fid__tmp)\
{ const uint8_t *buffer__tmp = C ## _ ## N(t__tmp); return __flatbuffers_read_root(T, K, buffer__tmp, fid__tmp); }\
static inline T ## _ ## K ## t C ## _ ## N ## _as_typed_root(C ## _ ## table_t t__tmp)\
{ const uint8_t *buffer__tmp = C ## _ ## N(t__tmp); return __flatbuffers_read_root(T, K, buffer__tmp, C ## _ ## type_identifier); }\
static inline T ## _ ## K ## t C ## _ ## N ## _as_root(C ## _ ## table_t t__tmp)\
{ const char *fid__tmp = T ## _file_identifier;\
  const uint8_t *buffer__tmp = C ## _ ## N(t__tmp); return __flatbuffers_read_root(T, K, buffer__tmp, fid__tmp); }
#define __flatbuffers_buffer_as_root(N, K)\
static inline N ## _ ## K ## t N ## _as_root_with_identifier(const void *buffer__tmp, const char *fid__tmp)\
{ return __flatbuffers_read_root(N, K, buffer__tmp, fid__tmp); }\
static inline N ## _ ## K ## t N ## _as_root_with_type_hash(const void *buffer__tmp, flatbuffers_thash_t thash__tmp)\
{ return __flatbuffers_read_typed_root(N, K, buffer__tmp, thash__tmp); }\
static inline N ## _ ## K ## t N ## _as_root(const void *buffer__tmp)\
{ const char *fid__tmp = N ## _file_identifier;\
  return __flatbuffers_read_root(N, K, buffer__tmp, fid__tmp); }\
static inline N ## _ ## K ## t N ## _as_typed_root(const void *buffer__tmp)\
{ return __flatbuffers_read_typed_root(N, K, buffer__tmp, N ## _type_hash); }
#define __flatbuffers_struct_as_root(N) __flatbuffers_buffer_as_root(N, struct_)
#define __flatbuffers_table_as_root(N) __flatbuffers_buffer_as_root(N, table_)

#include "flatcc/flatcc_epilogue.h"
#endif /* FLATBUFFERS_COMMON_H */
#ifndef FLATBUFFERS_COMMON_BUILDER_H
#define FLATBUFFERS_COMMON_BUILDER_H

/* Generated by flatcc 0.6.2 FlatBuffers schema compiler for C by dvide.com */

/* Common FlatBuffers build functionality for C. */

#include "flatcc/flatcc_prologue.h"
#ifndef FLATBUILDER_H
#include "flatcc/flatcc_builder.h"
#endif
typedef flatcc_builder_t flatbuffers_builder_t;
typedef flatcc_builder_ref_t flatbuffers_ref_t;
typedef flatcc_builder_ref_t flatbuffers_vec_ref_t;
typedef flatcc_builder_union_ref_t flatbuffers_union_ref_t;
typedef flatcc_builder_union_vec_ref_t flatbuffers_union_vec_ref_t;
/* integer return code (ref and ptr always fail on 0) */
#define flatbuffers_failed(x) ((x) < 0)
typedef flatbuffers_ref_t flatbuffers_root_t;
#define flatbuffers_root(ref) ((flatbuffers_root_t)(ref))

#define __flatbuffers_memoize_begin(B, src)\
do { flatcc_builder_ref_t _ref; if ((_ref = flatcc_builder_refmap_find((B), (src)))) return _ref; } while (0)
#define __flatbuffers_memoize_end(B, src, op) do { return flatcc_builder_refmap_insert((B), (src), (op)); } while (0)
#define __flatbuffers_memoize(B, src, op) do { __flatbuffers_memoize_begin(B, src); __flatbuffers_memoize_end(B, src, op); } while (0)

#define __flatbuffers_build_buffer(NS)\
typedef NS ## ref_t NS ## buffer_ref_t;\
static inline int NS ## buffer_start(NS ## builder_t *B, const NS ##fid_t fid)\
{ return flatcc_builder_start_buffer(B, fid, 0, 0); }\
static inline int NS ## buffer_start_with_size(NS ## builder_t *B, const NS ##fid_t fid)\
{ return flatcc_builder_start_buffer(B, fid, 0, flatcc_builder_with_size); }\
static inline int NS ## buffer_start_aligned(NS ## builder_t *B, NS ##fid_t fid, uint16_t block_align)\
{ return flatcc_builder_start_buffer(B, fid, block_align, 0); }\
static inline int NS ## buffer_start_aligned_with_size(NS ## builder_t *B, NS ##fid_t fid, uint16_t block_align)\
{ return flatcc_builder_start_buffer(B, fid, block_align, flatcc_builder_with_size); }\
static inline NS ## buffer_ref_t NS ## buffer_end(NS ## builder_t *B, NS ## ref_t root)\
{ return flatcc_builder_end_buffer(B, root); }

#define __flatbuffers_build_table_root(NS, N, FID, TFID)\
static inline int N ## _start_as_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, FID) ? -1 : N ## _start(B); }\
static inline int N ## _start_as_root_with_size(NS ## builder_t *B)\
{ return NS ## buffer_start_with_size(B, FID) ? -1 : N ## _start(B); }\
static inline int N ## _start_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, TFID) ? -1 : N ## _start(B); }\
static inline int N ## _start_as_typed_root_with_size(NS ## builder_t *B)\
{ return NS ## buffer_start_with_size(B, TFID) ? -1 : N ## _start(B); }\
static inline NS ## buffer_ref_t N ## _end_as_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end(B)); }\
static inline NS ## buffer_ref_t N ## _end_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end(B)); }\
static inline NS ## buffer_ref_t N ## _create_as_root(NS ## builder_t *B __ ## N ## _formal_args)\
{ if (NS ## buffer_start(B, FID)) return 0; return NS ## buffer_end(B, N ## _create(B __ ## N ## _call_args)); }\
static inline NS ## buffer_ref_t N ## _create_as_root_with_size(NS ## builder_t *B __ ## N ## _formal_args)\
{ if (NS ## buffer_start_with_size(B, FID)) return 0; return NS ## buffer_end(B, N ## _create(B __ ## N ## _call_args)); }\
static inline NS ## buffer_ref_t N ## _create_as_typed_root(NS ## builder_t *B __ ## N ## _formal_args)\
{ if (NS ## buffer_start(B, TFID)) return 0; return NS ## buffer_end(B, N ## _create(B __ ## N ## _call_args)); }\
static inline NS ## buffer_ref_t N ## _create_as_typed_root_with_size(NS ## builder_t *B __ ## N ## _formal_args)\
{ if (NS ## buffer_start_with_size(B, TFID)) return 0; return NS ## buffer_end(B, N ## _create(B __ ## N ## _call_args)); }\
static inline NS ## buffer_ref_t N ## _clone_as_root(NS ## builder_t *B, N ## _table_t t)\
{ if (NS ## buffer_start(B, FID)) return 0; return NS ## buffer_end(B, N ## _clone(B, t)); }\
static inline NS ## buffer_ref_t N ## _clone_as_root_with_size(NS ## builder_t *B, N ## _table_t t)\
{ if (NS ## buffer_start_with_size(B, FID)) return 0; return NS ## buffer_end(B, N ## _clone(B, t)); }\
static inline NS ## buffer_ref_t N ## _clone_as_typed_root(NS ## builder_t *B, N ## _table_t t)\
{ if (NS ## buffer_start(B, TFID)) return 0;return NS ## buffer_end(B, N ## _clone(B, t)); }\
static inline NS ## buffer_ref_t N ## _clone_as_typed_root_with_size(NS ## builder_t *B, N ## _table_t t)\
{ if (NS ## buffer_start_with_size(B, TFID)) return 0; return NS ## buffer_end(B, N ## _clone(B, t)); }

#define __flatbuffers_build_table_prolog(NS, N, FID, TFID)\
__flatbuffers_build_table_vector_ops(NS, N ## _vec, N)\
__flatbuffers_build_table_root(NS, N, FID, TFID)

#define __flatbuffers_build_struct_root(NS, N, A, FID, TFID)\
static inline N ## _t *N ## _start_as_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, FID) ? 0 : N ## _start(B); }\
static inline N ## _t *N ## _start_as_root_with_size(NS ## builder_t *B)\
{ return NS ## buffer_start_with_size(B, FID) ? 0 : N ## _start(B); }\
static inline N ## _t *N ## _start_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, TFID) ? 0 : N ## _start(B); }\
static inline N ## _t *N ## _start_as_typed_root_with_size(NS ## builder_t *B)\
{ return NS ## buffer_start_with_size(B, TFID) ? 0 : N ## _start(B); }\
static inline NS ## buffer_ref_t N ## _end_as_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end(B)); }\
static inline NS ## buffer_ref_t N ## _end_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end(B)); }\
static inline NS ## buffer_ref_t N ## _end_pe_as_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end_pe(B)); }\
static inline NS ## buffer_ref_t N ## _end_pe_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_end(B, N ## _end_pe(B)); }\
static inline NS ## buffer_ref_t N ## _create_as_root(NS ## builder_t *B __ ## N ## _formal_args)\
{ return flatcc_builder_create_buffer(B, FID, 0,\
  N ## _create(B __ ## N ## _call_args), A, 0); }\
static inline NS ## buffer_ref_t N ## _create_as_root_with_size(NS ## builder_t *B __ ## N ## _formal_args)\
{ return flatcc_builder_create_buffer(B, FID, 0,\
  N ## _create(B __ ## N ## _call_args), A, flatcc_builder_with_size); }\
static inline NS ## buffer_ref_t N ## _create_as_typed_root(NS ## builder_t *B __ ## N ## _formal_args)\
{ return flatcc_builder_create_buffer(B, TFID, 0,\
  N ## _create(B __ ## N ## _call_args), A, 0); }\
static inline NS ## buffer_ref_t N ## _create_as_typed_root_with_size(NS ## builder_t *B __ ## N ## _formal_args)\
{ return flatcc_builder_create_buffer(B, TFID, 0,\
  N ## _create(B __ ## N ## _call_args), A, flatcc_builder_with_size); }\
static inline NS ## buffer_ref_t N ## _clone_as_root(NS ## builder_t *B, N ## _struct_t p)\
{ return flatcc_builder_create_buffer(B, FID, 0, N ## _clone(B, p), A, 0); }\
static inline NS ## buffer_ref_t N ## _clone_as_root_with_size(NS ## builder_t *B, N ## _struct_t p)\
{ return flatcc_builder_create_buffer(B, FID, 0, N ## _clone(B, p), A, flatcc_builder_with_size); }\
static inline NS ## buffer_ref_t N ## _clone_as_typed_root(NS ## builder_t *B, N ## _struct_t p)\
{ return flatcc_builder_create_buffer(B, TFID, 0, N ## _clone(B, p), A, 0); }\
static inline NS ## buffer_ref_t N ## _clone_as_typed_root_with_size(NS ## builder_t *B, N ## _struct_t p)\
{ return flatcc_builder_create_buffer(B, TFID, 0, N ## _clone(B, p), A, flatcc_builder_with_size); }

#define __flatbuffers_build_nested_table_root(NS, N, TN, FID, TFID)\
static inline int N ## _start_as_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, FID) ? -1 : TN ## _start(B); }\
static inline int N ## _start_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, TFID) ? -1 : TN ## _start(B); }\
static inline int N ## _end_as_root(NS ## builder_t *B)\
{ return N ## _add(B, NS ## buffer_end(B, TN ## _end(B))); }\
static inline int N ## _end_as_typed_root(NS ## builder_t *B)\
{ return N ## _add(B, NS ## buffer_end(B, TN ## _end(B))); }\
static inline int N ## _nest(NS ## builder_t *B, void *data, size_t size, uint16_t align)\
{ return N ## _add(B, flatcc_builder_create_vector(B, data, size, 1,\
  align ? align : 8, FLATBUFFERS_COUNT_MAX(1))); }\
static inline int N ## _typed_nest(NS ## builder_t *B, void *data, size_t size, uint16_t align)\
{ return N ## _add(B, flatcc_builder_create_vector(B, data, size, 1,\
  align ? align : 8, FLATBUFFERS_COUNT_MAX(1))); }\
static inline int N ## _clone_as_root(NS ## builder_t *B, TN ## _table_t t)\
{ return N ## _add(B, TN ## _clone_as_root(B, t)); }\
static inline int N ## _clone_as_typed_root(NS ## builder_t *B, TN ## _table_t t)\
{ return N ## _add(B, TN ## _clone_as_typed_root(B, t)); }

#define __flatbuffers_build_nested_struct_root(NS, N, TN, A, FID, TFID)\
static inline TN ## _t *N ## _start_as_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, FID) ? 0 : TN ## _start(B); }\
static inline TN ## _t *N ## _start_as_typed_root(NS ## builder_t *B)\
{ return NS ## buffer_start(B, FID) ? 0 : TN ## _start(B); }\
static inline int N ## _end_as_root(NS ## builder_t *B)\
{ return N ## _add(B, NS ## buffer_end(B, TN ## _end(B))); }\
static inline int N ## _end_as_typed_root(NS ## builder_t *B)\
{ return N ## _add(B, NS ## buffer_end(B, TN ## _end(B))); }\
static inline int N ## _end_pe_as_root(NS ## builder_t *B)\
{ return N ## _add(B, NS ## buffer_end(B, TN ## _end_pe(B))); }\
static inline int N ## _create_as_root(NS ## builder_t *B __ ## TN ## _formal_args)\
{ return N ## _add(B, flatcc_builder_create_buffer(B, FID, 0,\
  TN ## _create(B __ ## TN ## _call_args), A, flatcc_builder_is_nested)); }\
static inline int N ## _create_as_typed_root(NS ## builder_t *B __ ## TN ## _formal_args)\
{ return N ## _add(B, flatcc_builder_create_buffer(B, TFID, 0,\
  TN ## _create(B __ ## TN ## _call_args), A, flatcc_builder_is_nested)); }\
static inline int N ## _nest(NS ## builder_t *B, void *data, size_t size, uint16_t align)\
{ return N ## _add(B, flatcc_builder_create_vector(B, data, size, 1,\
  align < A ? A : align, FLATBUFFERS_COUNT_MAX(1))); }\
static inline int N ## _typed_nest(NS ## builder_t *B, void *data, size_t size, uint16_t align)\
{ return N ## _add(B, flatcc_builder_create_vector(B, data, size, 1,\
  align < A ? A : align, FLATBUFFERS_COUNT_MAX(1))); }\
static inline int N ## _clone_as_root(NS ## builder_t *B, TN ## _struct_t p)\
{ return N ## _add(B, TN ## _clone_as_root(B, p)); }\
static inline int N ## _clone_as_typed_root(NS ## builder_t *B, TN ## _struct_t p)\
{ return N ## _add(B, TN ## _clone_as_typed_root(B, p)); }

#define __flatbuffers_build_vector_ops(NS, V, N, TN, T)\
static inline T *V ## _extend(NS ## builder_t *B, size_t len)\
{ return (T *)flatcc_builder_extend_vector(B, len); }\
static inline T *V ## _append(NS ## builder_t *B, const T *data, size_t len)\
{ return (T *)flatcc_builder_append_vector(B, data, len); }\
static inline int V ## _truncate(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_truncate_vector(B, len); }\
static inline T *V ## _edit(NS ## builder_t *B)\
{ return (T *)flatcc_builder_vector_edit(B); }\
static inline size_t V ## _reserved_len(NS ## builder_t *B)\
{ return flatcc_builder_vector_count(B); }\
static inline T *V ## _push(NS ## builder_t *B, const T *p)\
{ T *_p; return (_p = (T *)flatcc_builder_extend_vector(B, 1)) ? (memcpy(_p, p, TN ## __size()), _p) : 0; }\
static inline T *V ## _push_copy(NS ## builder_t *B, const T *p)\
{ T *_p; return (_p = (T *)flatcc_builder_extend_vector(B, 1)) ? TN ## _copy(_p, p) : 0; }\
static inline T *V ## _push_clone(NS ## builder_t *B, const T *p)\
{ T *_p; return (_p = (T *)flatcc_builder_extend_vector(B, 1)) ? TN ## _copy(_p, p) : 0; }\
static inline T *V ## _push_create(NS ## builder_t *B __ ## TN ## _formal_args)\
{ T *_p; return (_p = (T *)flatcc_builder_extend_vector(B, 1)) ? TN ## _assign(_p __ ## TN ## _call_args) : 0; }

#define __flatbuffers_build_vector(NS, N, T, S, A)\
typedef NS ## ref_t N ## _vec_ref_t;\
static inline int N ## _vec_start(NS ## builder_t *B)\
{ return flatcc_builder_start_vector(B, S, A, FLATBUFFERS_COUNT_MAX(S)); }\
static inline N ## _vec_ref_t N ## _vec_end_pe(NS ## builder_t *B)\
{ return flatcc_builder_end_vector(B); }\
static inline N ## _vec_ref_t N ## _vec_end(NS ## builder_t *B)\
{ if (!NS ## is_native_pe()) { size_t i, n; T *p = (T *)flatcc_builder_vector_edit(B);\
    for (i = 0, n = flatcc_builder_vector_count(B); i < n; ++i)\
    { N ## _to_pe(N ## __ptr_add(p, i)); }} return flatcc_builder_end_vector(B); }\
static inline N ## _vec_ref_t N ## _vec_create_pe(NS ## builder_t *B, const T *data, size_t len)\
{ return flatcc_builder_create_vector(B, data, len, S, A, FLATBUFFERS_COUNT_MAX(S)); }\
static inline N ## _vec_ref_t N ## _vec_create(NS ## builder_t *B, const T *data, size_t len)\
{ if (!NS ## is_native_pe()) { size_t i; T *p; int ret = flatcc_builder_start_vector(B, S, A, FLATBUFFERS_COUNT_MAX(S)); if (ret) { return ret; }\
  p = (T *)flatcc_builder_extend_vector(B, len); if (!p) return 0;\
  for (i = 0; i < len; ++i) { N ## _copy_to_pe(N ## __ptr_add(p, i), N ## __const_ptr_add(data, i)); }\
  return flatcc_builder_end_vector(B); } else return flatcc_builder_create_vector(B, data, len, S, A, FLATBUFFERS_COUNT_MAX(S)); }\
static inline N ## _vec_ref_t N ## _vec_clone(NS ## builder_t *B, N ##_vec_t vec)\
{ __flatbuffers_memoize(B, vec, flatcc_builder_create_vector(B, vec, N ## _vec_len(vec), S, A, FLATBUFFERS_COUNT_MAX(S))); }\
static inline N ## _vec_ref_t N ## _vec_slice(NS ## builder_t *B, N ##_vec_t vec, size_t index, size_t len)\
{ size_t n = N ## _vec_len(vec); if (index >= n) index = n; n -= index; if (len > n) len = n;\
  return flatcc_builder_create_vector(B, N ## __const_ptr_add(vec, index), len, S, A, FLATBUFFERS_COUNT_MAX(S)); }\
__flatbuffers_build_vector_ops(NS, N ## _vec, N, N, T)

#define __flatbuffers_build_union_vector_ops(NS, V, N, TN)\
static inline TN ## _union_ref_t *V ## _extend(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_extend_union_vector(B, len); }\
static inline TN ## _union_ref_t *V ## _append(NS ## builder_t *B, const TN ## _union_ref_t *data, size_t len)\
{ return flatcc_builder_append_union_vector(B, data, len); }\
static inline int V ## _truncate(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_truncate_union_vector(B, len); }\
static inline TN ## _union_ref_t *V ## _edit(NS ## builder_t *B)\
{ return (TN ## _union_ref_t *) flatcc_builder_union_vector_edit(B); }\
static inline size_t V ## _reserved_len(NS ## builder_t *B)\
{ return flatcc_builder_union_vector_count(B); }\
static inline TN ## _union_ref_t *V ## _push(NS ## builder_t *B, const TN ## _union_ref_t ref)\
{ return flatcc_builder_union_vector_push(B, ref); }\
static inline TN ## _union_ref_t *V ## _push_clone(NS ## builder_t *B, TN ## _union_t u)\
{ return TN ## _vec_push(B, TN ## _clone(B, u)); }

#define __flatbuffers_build_union_vector(NS, N)\
static inline int N ## _vec_start(NS ## builder_t *B)\
{ return flatcc_builder_start_union_vector(B); }\
static inline N ## _union_vec_ref_t N ## _vec_end(NS ## builder_t *B)\
{ return flatcc_builder_end_union_vector(B); }\
static inline N ## _union_vec_ref_t N ## _vec_create(NS ## builder_t *B, const N ## _union_ref_t *data, size_t len)\
{ return flatcc_builder_create_union_vector(B, data, len); }\
__flatbuffers_build_union_vector_ops(NS, N ## _vec, N, N)\
/* Preserves DAG structure separately for type and value vector, so a type vector could be shared for many value vectors. */\
static inline N ## _union_vec_ref_t N ## _vec_clone(NS ## builder_t *B, N ##_union_vec_t vec)\
{ N ## _union_vec_ref_t _uvref, _ret = { 0, 0 }; NS ## union_ref_t _uref; size_t _i, _len;\
  if (vec.type == 0) return _ret;\
  _uvref.type = flatcc_builder_refmap_find(B, vec.type); _uvref.value = flatcc_builder_refmap_find(B, vec.value);\
  _len = N ## _union_vec_len(vec); if (_uvref.type == 0) {\
  _uvref.type = flatcc_builder_refmap_insert(B, vec.type, (flatcc_builder_create_type_vector(B, vec.type, _len))); }\
  if (_uvref.type == 0) return _ret; if (_uvref.value == 0) {\
  if (flatcc_builder_start_offset_vector(B)) return _ret;\
  for (_i = 0; _i < _len; ++_i) { _uref = N ## _clone(B, N ## _union_vec_at(vec, _i));\
    if (!_uref.value || !(flatcc_builder_offset_vector_push(B, _uref.value))) return _ret; }\
  _uvref.value = flatcc_builder_refmap_insert(B, vec.value, flatcc_builder_end_offset_vector(B));\
  if (_uvref.value == 0) return _ret; } return _uvref; }

#define __flatbuffers_build_string_vector_ops(NS, N)\
static inline int N ## _push_start(NS ## builder_t *B)\
{ return NS ## string_start(B); }\
static inline NS ## string_ref_t *N ## _push_end(NS ## builder_t *B)\
{ return NS ## string_vec_push(B, NS ## string_end(B)); }\
static inline NS ## string_ref_t *N ## _push_create(NS ## builder_t *B, const char *s, size_t len)\
{ return NS ## string_vec_push(B, NS ## string_create(B, s, len)); }\
static inline NS ## string_ref_t *N ## _push_create_str(NS ## builder_t *B, const char *s)\
{ return NS ## string_vec_push(B, NS ## string_create_str(B, s)); }\
static inline NS ## string_ref_t *N ## _push_create_strn(NS ## builder_t *B, const char *s, size_t max_len)\
{ return NS ## string_vec_push(B, NS ## string_create_strn(B, s, max_len)); }\
static inline NS ## string_ref_t *N ## _push_clone(NS ## builder_t *B, NS ## string_t string)\
{ return NS ## string_vec_push(B, NS ## string_clone(B, string)); }\
static inline NS ## string_ref_t *N ## _push_slice(NS ## builder_t *B, NS ## string_t string, size_t index, size_t len)\
{ return NS ## string_vec_push(B, NS ## string_slice(B, string, index, len)); }

#define __flatbuffers_build_table_vector_ops(NS, N, TN)\
static inline int N ## _push_start(NS ## builder_t *B)\
{ return TN ## _start(B); }\
static inline TN ## _ref_t *N ## _push_end(NS ## builder_t *B)\
{ return N ## _push(B, TN ## _end(B)); }\
static inline TN ## _ref_t *N ## _push_create(NS ## builder_t *B __ ## TN ##_formal_args)\
{ return N ## _push(B, TN ## _create(B __ ## TN ## _call_args)); }

#define __flatbuffers_build_offset_vector_ops(NS, V, N, TN)\
static inline TN ## _ref_t *V ## _extend(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_extend_offset_vector(B, len); }\
static inline TN ## _ref_t *V ## _append(NS ## builder_t *B, const TN ## _ref_t *data, size_t len)\
{ return flatcc_builder_append_offset_vector(B, data, len); }\
static inline int V ## _truncate(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_truncate_offset_vector(B, len); }\
static inline TN ## _ref_t *V ## _edit(NS ## builder_t *B)\
{ return (TN ## _ref_t *)flatcc_builder_offset_vector_edit(B); }\
static inline size_t V ## _reserved_len(NS ## builder_t *B)\
{ return flatcc_builder_offset_vector_count(B); }\
static inline TN ## _ref_t *V ## _push(NS ## builder_t *B, const TN ## _ref_t ref)\
{ return ref ? flatcc_builder_offset_vector_push(B, ref) : 0; }

#define __flatbuffers_build_offset_vector(NS, N)\
typedef NS ## ref_t N ## _vec_ref_t;\
static inline int N ## _vec_start(NS ## builder_t *B)\
{ return flatcc_builder_start_offset_vector(B); }\
static inline N ## _vec_ref_t N ## _vec_end(NS ## builder_t *B)\
{ return flatcc_builder_end_offset_vector(B); }\
static inline N ## _vec_ref_t N ## _vec_create(NS ## builder_t *B, const N ## _ref_t *data, size_t len)\
{ return flatcc_builder_create_offset_vector(B, data, len); }\
__flatbuffers_build_offset_vector_ops(NS, N ## _vec, N, N)\
static inline N ## _vec_ref_t N ## _vec_clone(NS ## builder_t *B, N ##_vec_t vec)\
{ int _ret; N ## _ref_t _e; size_t _i, _len; __flatbuffers_memoize_begin(B, vec);\
 _len = N ## _vec_len(vec); if (flatcc_builder_start_offset_vector(B)) return 0;\
  for (_i = 0; _i < _len; ++_i) { if (!(_e = N ## _clone(B, N ## _vec_at(vec, _i)))) return 0;\
    if (!flatcc_builder_offset_vector_push(B, _e)) return 0; }\
  __flatbuffers_memoize_end(B, vec, flatcc_builder_end_offset_vector(B)); }\

#define __flatbuffers_build_string_ops(NS, N)\
static inline char *N ## _append(NS ## builder_t *B, const char *s, size_t len)\
{ return flatcc_builder_append_string(B, s, len); }\
static inline char *N ## _append_str(NS ## builder_t *B, const char *s)\
{ return flatcc_builder_append_string_str(B, s); }\
static inline char *N ## _append_strn(NS ## builder_t *B, const char *s, size_t len)\
{ return flatcc_builder_append_string_strn(B, s, len); }\
static inline size_t N ## _reserved_len(NS ## builder_t *B)\
{ return flatcc_builder_string_len(B); }\
static inline char *N ## _extend(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_extend_string(B, len); }\
static inline char *N ## _edit(NS ## builder_t *B)\
{ return flatcc_builder_string_edit(B); }\
static inline int N ## _truncate(NS ## builder_t *B, size_t len)\
{ return flatcc_builder_truncate_string(B, len); }

#define __flatbuffers_build_string(NS)\
typedef NS ## ref_t NS ## string_ref_t;\
static inline int NS ## string_start(NS ## builder_t *B)\
{ return flatcc_builder_start_string(B); }\
static inline NS ## string_ref_t NS ## string_end(NS ## builder_t *B)\
{ return flatcc_builder_end_string(B); }\
static inline NS ## ref_t NS ## string_create(NS ## builder_t *B, const char *s, size_t len)\
{ return flatcc_builder_create_string(B, s, len); }\
static inline NS ## ref_t NS ## string_create_str(NS ## builder_t *B, const char *s)\
{ return flatcc_builder_create_string_str(B, s); }\
static inline NS ## ref_t NS ## string_create_strn(NS ## builder_t *B, const char *s, size_t len)\
{ return flatcc_builder_create_string_strn(B, s, len); }\
static inline NS ## string_ref_t NS ## string_clone(NS ## builder_t *B, NS ## string_t string)\
{ __flatbuffers_memoize(B, string, flatcc_builder_create_string(B, string, NS ## string_len(string))); }\
static inline NS ## string_ref_t NS ## string_slice(NS ## builder_t *B, NS ## string_t string, size_t index, size_t len)\
{ size_t n = NS ## string_len(string); if (index >= n) index = n; n -= index; if (len > n) len = n;\
  return flatcc_builder_create_string(B, string + index, len); }\
__flatbuffers_build_string_ops(NS, NS ## string)\
__flatbuffers_build_offset_vector(NS, NS ## string)

#define __flatbuffers_copy_from_pe(P, P2, N) (*(P) = N ## _read_from_pe(P2), (P))
#define __flatbuffers_from_pe(P, N) (*(P) = N ## _read_from_pe(P), (P))
#define __flatbuffers_copy_to_pe(P, P2, N) (N ## _write_to_pe((P), *(P2)), (P))
#define __flatbuffers_to_pe(P, N) (N ## _write_to_pe((P), *(P)), (P))
#define __flatbuffers_define_fixed_array_primitives(NS, N, T)\
static inline T *N ## _array_copy(T *p, const T *p2, size_t n)\
{ memcpy(p, p2, n * sizeof(T)); return p; }\
static inline T *N ## _array_copy_from_pe(T *p, const T *p2, size_t n)\
{ size_t i; if (NS ## is_native_pe()) memcpy(p, p2, n * sizeof(T)); else\
  for (i = 0; i < n; ++i) N ## _copy_from_pe(&p[i], &p2[i]); return p; }\
static inline T *N ## _array_copy_to_pe(T *p, const T *p2, size_t n)\
{ size_t i; if (NS ## is_native_pe()) memcpy(p, p2, n * sizeof(T)); else\
  for (i = 0; i < n; ++i) N ## _copy_to_pe(&p[i], &p2[i]); return p; }
#define __flatbuffers_define_scalar_primitives(NS, N, T)\
static inline T *N ## _from_pe(T *p) { return __ ## NS ## from_pe(p, N); }\
static inline T *N ## _to_pe(T *p) { return __ ## NS ## to_pe(p, N); }\
static inline T *N ## _copy(T *p, const T *p2) { *p = *p2; return p; }\
static inline T *N ## _copy_from_pe(T *p, const T *p2)\
{ return __ ## NS ## copy_from_pe(p, p2, N); }\
static inline T *N ## _copy_to_pe(T *p, const T *p2) \
{ return __ ## NS ## copy_to_pe(p, p2, N); }\
static inline T *N ## _assign(T *p, const T v0) { *p = v0; return p; }\
static inline T *N ## _assign_from_pe(T *p, T v0)\
{ *p = N ## _read_from_pe(&v0); return p; }\
static inline T *N ## _assign_to_pe(T *p, T v0)\
{ N ## _write_to_pe(p, v0); return p; }
#define __flatbuffers_build_scalar(NS, N, T)\
__ ## NS ## define_scalar_primitives(NS, N, T)\
__ ## NS ## define_fixed_array_primitives(NS, N, T)\
__ ## NS ## build_vector(NS, N, T, sizeof(T), sizeof(T))
/* Depends on generated copy_to/from_pe functions, and the type. */
#define __flatbuffers_define_struct_primitives(NS, N)\
static inline N ## _t *N ##_to_pe(N ## _t *p)\
{ if (!NS ## is_native_pe()) { N ## _copy_to_pe(p, p); }; return p; }\
static inline N ## _t *N ##_from_pe(N ## _t *p)\
{ if (!NS ## is_native_pe()) { N ## _copy_from_pe(p, p); }; return p; }\
static inline N ## _t *N ## _clear(N ## _t *p) { return (N ## _t *)memset(p, 0, N ## __size()); }

/* Depends on generated copy/assign_to/from_pe functions, and the type. */
#define __flatbuffers_build_struct(NS, N, S, A, FID, TFID)\
__ ## NS ## define_struct_primitives(NS, N)\
typedef NS ## ref_t N ## _ref_t;\
static inline N ## _t *N ## _start(NS ## builder_t *B)\
{ return (N ## _t *)flatcc_builder_start_struct(B, S, A); }\
static inline N ## _ref_t N ## _end(NS ## builder_t *B)\
{ if (!NS ## is_native_pe()) { N ## _to_pe((N ## _t *)flatcc_builder_struct_edit(B)); }\
  return flatcc_builder_end_struct(B); }\
static inline N ## _ref_t N ## _end_pe(NS ## builder_t *B)\
{ return flatcc_builder_end_struct(B); }\
static inline N ## _ref_t N ## _create(NS ## builder_t *B __ ## N ## _formal_args)\
{ N ## _t *_p = N ## _start(B); if (!_p) return 0; N ##_assign_to_pe(_p __ ## N ## _call_args);\
  return N ## _end_pe(B); }\
static inline N ## _ref_t N ## _clone(NS ## builder_t *B, N ## _struct_t p)\
{ N ## _t *_p; __flatbuffers_memoize_begin(B, p); _p = N ## _start(B); if (!_p) return 0;\
  N ## _copy(_p, p); __flatbuffers_memoize_end(B, p, N ##_end_pe(B)); }\
__flatbuffers_build_vector(NS, N, N ## _t, S, A)\
__flatbuffers_build_struct_root(NS, N, A, FID, TFID)\

#define __flatbuffers_struct_clear_field(p) memset((p), 0, sizeof(*(p)))
#define __flatbuffers_build_table(NS, N, K)\
static inline int N ## _start(NS ## builder_t *B)\
{ return flatcc_builder_start_table(B, K); }\
static inline N ## _ref_t N ## _end(NS ## builder_t *B)\
{ FLATCC_ASSERT(flatcc_builder_check_required(B, __ ## N ## _required,\
  sizeof(__ ## N ## _required) / sizeof(__ ## N ## _required[0]) - 1));\
  return flatcc_builder_end_table(B); }\
__flatbuffers_build_offset_vector(NS, N)

#define __flatbuffers_build_table_field(ID, NS, N, TN, TT)\
static inline int N ## _add(NS ## builder_t *B, TN ## _ref_t ref)\
{ TN ## _ref_t *_p; return (ref && (_p = flatcc_builder_table_add_offset(B, ID))) ?\
  ((*_p = ref), 0) : -1; }\
static inline int N ## _start(NS ## builder_t *B)\
{ return TN ## _start(B); }\
static inline int N ## _end(NS ## builder_t *B)\
{ return N ## _add(B, TN ## _end(B)); }\
static inline TN ## _ref_t N ## _create(NS ## builder_t *B __ ## TN ##_formal_args)\
{ return N ## _add(B, TN ## _create(B __ ## TN ## _call_args)); }\
static inline int N ## _clone(NS ## builder_t *B, TN ## _table_t p)\
{ return N ## _add(B, TN ## _clone(B, p)); }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _table_t _p = N ## _get(t); return _p ? N ## _clone(B, _p) : 0; }

#define __flatbuffers_build_union_field(ID, NS, N, TN, TT)\
static inline int N ## _add(NS ## builder_t *B, TN ## _union_ref_t uref)\
{ NS ## ref_t *_p; TN ## _union_type_t *_pt; if (uref.type == TN ## _NONE) return 0; if (uref.value == 0) return -1;\
  if (!(_pt = (TN ## _union_type_t *)flatcc_builder_table_add(B, ID - 1, sizeof(*_pt), sizeof(*_pt)))) return -1;\
  *_pt = uref.type; if (!(_p = flatcc_builder_table_add_offset(B, ID))) return -1; *_p = uref.value; return 0; }\
static inline int N ## _add_type(NS ## builder_t *B, TN ## _union_type_t type)\
{ TN ## _union_type_t *_pt; if (type == TN ## _NONE) return 0; return (_pt = (TN ## _union_type_t *)flatcc_builder_table_add(B, ID - 1,\
  sizeof(*_pt), sizeof(*_pt))) ? ((*_pt = type), 0) : -1; }\
static inline int N ## _add_value(NS ## builder_t *B, TN ## _union_ref_t uref)\
{ NS ## ref_t *p; if (uref.type == TN ## _NONE) return 0; return (p = flatcc_builder_table_add_offset(B, ID)) ?\
  ((*p = uref.value), 0) : -1; }\
static inline int N ## _clone(NS ## builder_t *B, TN ## _union_t p)\
{ return N ## _add(B, TN ## _clone(B, p)); }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _union_t _p = N ## _union(t); return _p.type ? N ## _clone(B, _p) : 0; }

/* M is the union value name and T is its type, i.e. the qualified name. */
#define __flatbuffers_build_union_table_value_field(NS, N, NU, M, T)\
static inline int N ## _ ## M ## _add(NS ## builder_t *B, T ## _ref_t ref)\
{ return N ## _add(B, NU ## _as_ ## M (ref)); }\
static inline int N ## _ ## M ## _start(NS ## builder_t *B)\
{ return T ## _start(B); }\
static inline int N ## _ ## M ## _end(NS ## builder_t *B)\
{ T ## _ref_t ref = T ## _end(B);\
  return ref ? N ## _ ## M ## _add(B, ref) : -1; }\
static inline int N ## _ ## M ## _create(NS ## builder_t *B __ ## T ##_formal_args)\
{ T ## _ref_t ref = T ## _create(B __ ## T ## _call_args);\
  return ref ? N ## _add(B, NU ## _as_ ## M(ref)) : -1; }\
static inline int N ## _ ## M ## _clone(NS ## builder_t *B, T ## _table_t t)\
{ T ## _ref_t ref = T ## _clone(B, t);\
  return ref ? N ## _add(B, NU ## _as_ ## M(ref)) : -1; }

/* M is the union value name and T is its type, i.e. the qualified name. */
#define __flatbuffers_build_union_struct_value_field(NS, N, NU, M, T)\
static inline int N ## _ ## M ## _add(NS ## builder_t *B, T ## _ref_t ref)\
{ return N ## _add(B, NU ## _as_ ## M (ref)); }\
static inline T ## _t *N ## _ ## M ## _start(NS ## builder_t *B)\
{ return T ## _start(B); }\
static inline int N ## _ ## M ## _end(NS ## builder_t *B)\
{ T ## _ref_t ref = T ## _end(B);\
  return ref ? N ## _ ## M ## _add(B, ref) : -1; }\
static inline int N ## _ ## M ## _create(NS ## builder_t *B __ ## T ##_formal_args)\
{ T ## _ref_t ref = T ## _create(B __ ## T ## _call_args);\
  return ref ? N ## _add(B, NU ## _as_ ## M(ref)) : -1; }\
static inline int N ## _ ## M ## _end_pe(NS ## builder_t *B)\
{ T ## _ref_t ref = T ## _end_pe(B);\
  return ref ? N ## _add(B, NU ## _as_ ## M(ref)) : -1; }\
static inline int N ## _ ## M ## _clone(NS ## builder_t *B, T ## _struct_t p)\
{ T ## _ref_t ref = T ## _clone(B, p);\
  return ref ? N ## _add(B, NU ## _as_ ## M(ref)) : -1; }
#define __flatbuffers_build_union_string_value_field(NS, N, NU, M)\
static inline int N ## _ ## M ## _add(NS ## builder_t *B, NS ## string_ref_t ref)\
{ return N ## _add(B, NU ## _as_ ## M (ref)); }\
__flatbuffers_build_string_field_ops(NS, N ## _ ## M)

/* NS: common namespace, ID: table field id (not offset), TN: name of type T, TT: name of table type
 * S: sizeof of scalar type, A: alignment of type T, default value V of type T. */
#define __flatbuffers_build_scalar_field(ID, NS, N, TN, T, S, A, V, TT)\
static inline int N ## _add(NS ## builder_t *B, const T v)\
{ T *_p; if (v == V) return 0; if (!(_p = (T *)flatcc_builder_table_add(B, ID, S, A))) return -1;\
  TN ## _assign_to_pe(_p, v); return 0; }\
static inline int N ## _force_add(NS ## builder_t *B, const T v)\
{ T *_p; if (!(_p = (T *)flatcc_builder_table_add(B, ID, S, A))) return -1;\
  TN ## _assign_to_pe(_p, v); return 0; }\
/* Clone does not skip default values and expects pe endian content. */\
static inline int N ## _clone(NS ## builder_t *B, const T *p)\
{ return 0 == flatcc_builder_table_add_copy(B, ID, p, S, A) ? -1 : 0; }\
/* Transferring a missing field is a nop success with 0 as result. */\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ const T *_p = N ## _get_ptr(t); return _p ? N ## _clone(B, _p) : 0; }

/* NS: common namespace, ID: table field id (not offset), TN: name of type T, TT: name of table type
 * S: sizeof of scalar type, A: alignment of type T. */
#define __flatbuffers_build_scalar_optional_field(ID, NS, N, TN, T, S, A, TT)\
static inline int N ## _add(NS ## builder_t *B, const T v)\
{ T *_p; if (!(_p = (T *)flatcc_builder_table_add(B, ID, S, A))) return -1;\
  TN ## _assign_to_pe(_p, v); return 0; }\
/* Clone does not skip default values and expects pe endian content. */\
static inline int N ## _clone(NS ## builder_t *B, const T *p)\
{ return 0 == flatcc_builder_table_add_copy(B, ID, p, S, A) ? -1 : 0; }\
/* Transferring a missing field is a nop success with 0 as result. */\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ const T *_p = N ## _get_ptr(t); return _p ? N ## _clone(B, _p) : 0; }

#define __flatbuffers_build_struct_field(ID, NS, N, TN, S, A, TT)\
static inline TN ## _t *N ## _start(NS ## builder_t *B)\
{ return (TN ## _t *)flatcc_builder_table_add(B, ID, S, A); }\
static inline int N ## _end(NS ## builder_t *B)\
{ if (!NS ## is_native_pe()) { TN ## _to_pe((TN ## _t *)flatcc_builder_table_edit(B, S)); } return 0; }\
static inline int N ## _end_pe(NS ## builder_t *B) { return 0; }\
static inline int N ## _create(NS ## builder_t *B __ ## TN ## _formal_args)\
{ TN ## _t *_p = N ## _start(B); if (!_p) return -1; TN ##_assign_to_pe(_p __ ## TN ## _call_args);\
  return 0; }\
static inline int N ## _add(NS ## builder_t *B, const TN ## _t *p)\
{ TN ## _t *_p = N ## _start(B); if (!_p) return -1; TN ##_copy_to_pe(_p, p); return 0; }\
static inline int N ## _clone(NS ## builder_t *B, TN ## _struct_t p)\
{ return 0 == flatcc_builder_table_add_copy(B, ID, p, S, A) ? -1 : 0; }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _struct_t _p = N ## _get(t); return _p ? N ## _clone(B, _p) : 0; }

#define __flatbuffers_build_vector_field(ID, NS, N, TN, T, TT)\
static inline int N ## _add(NS ## builder_t *B, TN ## _vec_ref_t ref)\
{ TN ## _vec_ref_t *_p; return (ref && (_p = flatcc_builder_table_add_offset(B, ID))) ? ((*_p = ref), 0) : -1; }\
static inline int N ## _start(NS ## builder_t *B)\
{ return TN ## _vec_start(B); }\
static inline int N ## _end_pe(NS ## builder_t *B)\
{ return N ## _add(B, TN ## _vec_end_pe(B)); }\
static inline int N ## _end(NS ## builder_t *B)\
{ return N ## _add(B, TN ## _vec_end(B)); }\
static inline int N ## _create_pe(NS ## builder_t *B, const T *data, size_t len)\
{ return N ## _add(B, TN ## _vec_create_pe(B, data, len)); }\
static inline int N ## _create(NS ## builder_t *B, const T *data, size_t len)\
{ return N ## _add(B, TN ## _vec_create(B, data, len)); }\
static inline int N ## _slice(NS ## builder_t *B, TN ## _vec_t vec, size_t index, size_t len)\
{ return N ## _add(B, TN ## _vec_slice(B, vec, index, len)); }\
static inline int N ## _clone(NS ## builder_t *B, TN ## _vec_t vec)\
{ return N ## _add(B, TN ## _vec_clone(B, vec)); }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _vec_t _p = N ## _get(t); return _p ? N ## _clone(B, _p) : 0; }\
__flatbuffers_build_vector_ops(NS, N, N, TN, T)\

#define __flatbuffers_build_offset_vector_field(ID, NS, N, TN, TT)\
static inline int N ## _add(NS ## builder_t *B, TN ## _vec_ref_t ref)\
{ TN ## _vec_ref_t *_p; return (ref && (_p = flatcc_builder_table_add_offset(B, ID))) ? ((*_p = ref), 0) : -1; }\
static inline int N ## _start(NS ## builder_t *B)\
{ return flatcc_builder_start_offset_vector(B); }\
static inline int N ## _end(NS ## builder_t *B)\
{ return N ## _add(B, flatcc_builder_end_offset_vector(B)); }\
static inline int N ## _create(NS ## builder_t *B, const TN ## _ref_t *data, size_t len)\
{ return N ## _add(B, flatcc_builder_create_offset_vector(B, data, len)); }\
__flatbuffers_build_offset_vector_ops(NS, N, N, TN)\
static inline int N ## _clone(NS ## builder_t *B, TN ## _vec_t vec)\
{ return N ## _add(B, TN ## _vec_clone(B, vec)); }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _vec_t _p = N ## _get(t); return _p ? N ## _clone(B, _p) : 0; }

/* depends on N ## _add which differs for union member fields and ordinary fields */\
#define __flatbuffers_build_string_field_ops(NS, N)\
static inline int N ## _start(NS ## builder_t *B)\
{ return flatcc_builder_start_string(B); }\
static inline int N ## _end(NS ## builder_t *B)\
{ return N ## _add(B, flatcc_builder_end_string(B)); }\
static inline int N ## _create(NS ## builder_t *B, const char *s, size_t len)\
{ return N ## _add(B, flatcc_builder_create_string(B, s, len)); }\
static inline int N ## _create_str(NS ## builder_t *B, const char *s)\
{ return N ## _add(B, flatcc_builder_create_string_str(B, s)); }\
static inline int N ## _create_strn(NS ## builder_t *B, const char *s, size_t max_len)\
{ return N ## _add(B, flatcc_builder_create_string_strn(B, s, max_len)); }\
static inline int N ## _clone(NS ## builder_t *B, NS ## string_t string)\
{ return N ## _add(B, NS ## string_clone(B, string)); }\
static inline int N ## _slice(NS ## builder_t *B, NS ## string_t string, size_t index, size_t len)\
{ return N ## _add(B, NS ## string_slice(B, string, index, len)); }\
__flatbuffers_build_string_ops(NS, N)

#define __flatbuffers_build_string_field(ID, NS, N, TT)\
static inline int N ## _add(NS ## builder_t *B, NS ## string_ref_t ref)\
{ NS ## string_ref_t *_p; return (ref && (_p = flatcc_builder_table_add_offset(B, ID))) ? ((*_p = ref), 0) : -1; }\
__flatbuffers_build_string_field_ops(NS, N)\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ NS ## string_t _p = N ## _get(t); return _p ? N ## _clone(B, _p) : 0; }

#define __flatbuffers_build_table_vector_field(ID, NS, N, TN, TT)\
__flatbuffers_build_offset_vector_field(ID, NS, N, TN, TT)\
__flatbuffers_build_table_vector_ops(NS, N, TN)

#define __flatbuffers_build_union_vector_field(ID, NS, N, TN, TT)\
static inline int N ## _add(NS ## builder_t *B, TN ## _union_vec_ref_t uvref)\
{ NS ## vec_ref_t *_p; if (!uvref.type || !uvref.value) return uvref.type == uvref.value ? 0 : -1;\
  if (!(_p = flatcc_builder_table_add_offset(B, ID - 1))) return -1; *_p = uvref.type;\
  if (!(_p = flatcc_builder_table_add_offset(B, ID))) return -1; *_p = uvref.value; return 0; }\
static inline int N ## _start(NS ## builder_t *B)\
{ return flatcc_builder_start_union_vector(B); }\
static inline int N ## _end(NS ## builder_t *B)\
{ return N ## _add(B, flatcc_builder_end_union_vector(B)); }\
static inline int N ## _create(NS ## builder_t *B, const TN ## _union_ref_t *data, size_t len)\
{ return N ## _add(B, flatcc_builder_create_union_vector(B, data, len)); }\
__flatbuffers_build_union_vector_ops(NS, N, N, TN)\
static inline int N ## _clone(NS ## builder_t *B, TN ## _union_vec_t vec)\
{ return N ## _add(B, TN ## _vec_clone(B, vec)); }\
static inline int N ## _pick(NS ## builder_t *B, TT ## _table_t t)\
{ TN ## _union_vec_t _p = N ## _union(t); return _p.type ? N ## _clone(B, _p) : 0; }

#define __flatbuffers_build_union_table_vector_value_field(NS, N, NU, M, T)\
static inline int N ## _ ## M ## _push_start(NS ## builder_t *B)\
{ return T ## _start(B); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_end(NS ## builder_t *B)\
{ return NU ## _vec_push(B, NU ## _as_ ## M (T ## _end(B))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push(NS ## builder_t *B, T ## _ref_t ref)\
{ return NU ## _vec_push(B, NU ## _as_ ## M (ref)); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_create(NS ## builder_t *B __ ## T ##_formal_args)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(T ## _create(B __ ## T ## _call_args))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_clone(NS ## builder_t *B, T ## _table_t t)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(T ## _clone(B, t))); }

#define __flatbuffers_build_union_struct_vector_value_field(NS, N, NU, M, T)\
static inline T ## _t *N ## _ ## M ## _push_start(NS ## builder_t *B)\
{ return T ## _start(B); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_end(NS ## builder_t *B)\
{ return NU ## _vec_push(B, NU ## _as_ ## M (T ## _end(B))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push(NS ## builder_t *B, T ## _ref_t ref)\
{ return NU ## _vec_push(B, NU ## _as_ ## M (ref)); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_create(NS ## builder_t *B __ ## T ##_formal_args)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(T ## _create(B __ ## T ## _call_args))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_clone(NS ## builder_t *B, T ## _struct_t p)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(T ## _clone(B, p))); }

#define __flatbuffers_build_union_string_vector_value_field(NS, N, NU, M)\
static inline NU ## _union_ref_t *N ## _ ## M ## _push(NS ## builder_t *B, NS ## string_ref_t ref)\
{ return NU ## _vec_push(B, NU ## _as_ ## M (ref)); }\
static inline int N ## _ ## M ## _push_start(NS ## builder_t *B)\
{ return NS ## string_start(B); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_end(NS ## builder_t *B)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_end(B))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_create(NS ## builder_t *B, const char *s, size_t len)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_create(B, s, len))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_create_str(NS ## builder_t *B, const char *s)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_create_str(B, s))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_create_strn(NS ## builder_t *B, const char *s, size_t max_len)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_create_strn(B, s, max_len))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_clone(NS ## builder_t *B, NS ## string_t string)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_clone(B, string))); }\
static inline NU ## _union_ref_t *N ## _ ## M ## _push_slice(NS ## builder_t *B, NS ## string_t string, size_t index, size_t len)\
{ return NU ## _vec_push(B, NU ## _as_ ## M(NS ## string_slice(B, string, index, len))); }

#define __flatbuffers_build_string_vector_field(ID, NS, N, TT)\
__flatbuffers_build_offset_vector_field(ID, NS, N, NS ## string, TT)\
__flatbuffers_build_string_vector_ops(NS, N)

#define __flatbuffers_char_formal_args , char v0
#define __flatbuffers_char_call_args , v0
#define __flatbuffers_uint8_formal_args , uint8_t v0
#define __flatbuffers_uint8_call_args , v0
#define __flatbuffers_int8_formal_args , int8_t v0
#define __flatbuffers_int8_call_args , v0
#define __flatbuffers_bool_formal_args , flatbuffers_bool_t v0
#define __flatbuffers_bool_call_args , v0
#define __flatbuffers_uint16_formal_args , uint16_t v0
#define __flatbuffers_uint16_call_args , v0
#define __flatbuffers_uint32_formal_args , uint32_t v0
#define __flatbuffers_uint32_call_args , v0
#define __flatbuffers_uint64_formal_args , uint64_t v0
#define __flatbuffers_uint64_call_args , v0
#define __flatbuffers_int16_formal_args , int16_t v0
#define __flatbuffers_int16_call_args , v0
#define __flatbuffers_int32_formal_args , int32_t v0
#define __flatbuffers_int32_call_args , v0
#define __flatbuffers_int64_formal_args , int64_t v0
#define __flatbuffers_int64_call_args , v0
#define __flatbuffers_float_formal_args , float v0
#define __flatbuffers_float_call_args , v0
#define __flatbuffers_double_formal_args , double v0
#define __flatbuffers_double_call_args , v0

__flatbuffers_build_scalar(flatbuffers_, flatbuffers_char, char)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_uint8, uint8_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_int8, int8_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_bool, flatbuffers_bool_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_uint16, uint16_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_uint32, uint32_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_uint64, uint64_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_int16, int16_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_int32, int32_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_int64, int64_t)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_float, float)
__flatbuffers_build_scalar(flatbuffers_, flatbuffers_double, double)

__flatbuffers_build_string(flatbuffers_)

__flatbuffers_build_buffer(flatbuffers_)
#include "flatcc/flatcc_epilogue.h"
#endif /* FLATBUFFERS_COMMON_BUILDER_H */
#ifndef ETM_READER_H
#define ETM_READER_H

/* Generated by flatcc 0.6.2 FlatBuffers schema compiler for C by dvide.com */

#ifndef FLATBUFFERS_COMMON_READER_H
#include "flatbuffers_common_reader.h"
#endif
#include "flatcc/flatcc_flatbuffers.h"
#ifndef __alignas_is_defined
#include <stdalign.h>
#endif
#include "flatcc/flatcc_prologue.h"
#ifndef flatbuffers_identifier
#define flatbuffers_identifier 0
#endif
#ifndef flatbuffers_extension
#define flatbuffers_extension "bin"
#endif


typedef const struct etm_Tensor_table *etm_Tensor_table_t;
typedef struct etm_Tensor_table *etm_Tensor_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Tensor_vec_t;
typedef flatbuffers_uoffset_t *etm_Tensor_mutable_vec_t;
typedef const struct etm_Attribute_table *etm_Attribute_table_t;
typedef struct etm_Attribute_table *etm_Attribute_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Attribute_vec_t;
typedef flatbuffers_uoffset_t *etm_Attribute_mutable_vec_t;
typedef const struct etm_Node_table *etm_Node_table_t;
typedef struct etm_Node_table *etm_Node_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Node_vec_t;
typedef flatbuffers_uoffset_t *etm_Node_mutable_vec_t;
typedef const struct etm_PGraphInfo_table *etm_PGraphInfo_table_t;
typedef struct etm_PGraphInfo_table *etm_PGraphInfo_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_PGraphInfo_vec_t;
typedef flatbuffers_uoffset_t *etm_PGraphInfo_mutable_vec_t;
typedef const struct etm_SGraphInfo_table *etm_SGraphInfo_table_t;
typedef struct etm_SGraphInfo_table *etm_SGraphInfo_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_SGraphInfo_vec_t;
typedef flatbuffers_uoffset_t *etm_SGraphInfo_mutable_vec_t;
typedef const struct etm_Graph_table *etm_Graph_table_t;
typedef struct etm_Graph_table *etm_Graph_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Graph_vec_t;
typedef flatbuffers_uoffset_t *etm_Graph_mutable_vec_t;
typedef const struct etm_Op_table *etm_Op_table_t;
typedef struct etm_Op_table *etm_Op_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Op_vec_t;
typedef flatbuffers_uoffset_t *etm_Op_mutable_vec_t;
typedef const struct etm_Model_table *etm_Model_table_t;
typedef struct etm_Model_table *etm_Model_mutable_table_t;
typedef const flatbuffers_uoffset_t *etm_Model_vec_t;
typedef flatbuffers_uoffset_t *etm_Model_mutable_vec_t;
#ifndef etm_Tensor_file_identifier
#define etm_Tensor_file_identifier 0
#endif
/* deprecated, use etm_Tensor_file_identifier */
#ifndef etm_Tensor_identifier
#define etm_Tensor_identifier 0
#endif
#define etm_Tensor_type_hash ((flatbuffers_thash_t)0x4bf3c3e)
#define etm_Tensor_type_identifier "\x3e\x3c\xbf\x04"
#ifndef etm_Tensor_file_extension
#define etm_Tensor_file_extension "bin"
#endif
#ifndef etm_Attribute_file_identifier
#define etm_Attribute_file_identifier 0
#endif
/* deprecated, use etm_Attribute_file_identifier */
#ifndef etm_Attribute_identifier
#define etm_Attribute_identifier 0
#endif
#define etm_Attribute_type_hash ((flatbuffers_thash_t)0x8d6eee2d)
#define etm_Attribute_type_identifier "\x2d\xee\x6e\x8d"
#ifndef etm_Attribute_file_extension
#define etm_Attribute_file_extension "bin"
#endif
#ifndef etm_Node_file_identifier
#define etm_Node_file_identifier 0
#endif
/* deprecated, use etm_Node_file_identifier */
#ifndef etm_Node_identifier
#define etm_Node_identifier 0
#endif
#define etm_Node_type_hash ((flatbuffers_thash_t)0x8a7a3df7)
#define etm_Node_type_identifier "\xf7\x3d\x7a\x8a"
#ifndef etm_Node_file_extension
#define etm_Node_file_extension "bin"
#endif
#ifndef etm_PGraphInfo_file_identifier
#define etm_PGraphInfo_file_identifier 0
#endif
/* deprecated, use etm_PGraphInfo_file_identifier */
#ifndef etm_PGraphInfo_identifier
#define etm_PGraphInfo_identifier 0
#endif
#define etm_PGraphInfo_type_hash ((flatbuffers_thash_t)0xf5d80ce3)
#define etm_PGraphInfo_type_identifier "\xe3\x0c\xd8\xf5"
#ifndef etm_PGraphInfo_file_extension
#define etm_PGraphInfo_file_extension "bin"
#endif
#ifndef etm_SGraphInfo_file_identifier
#define etm_SGraphInfo_file_identifier 0
#endif
/* deprecated, use etm_SGraphInfo_file_identifier */
#ifndef etm_SGraphInfo_identifier
#define etm_SGraphInfo_identifier 0
#endif
#define etm_SGraphInfo_type_hash ((flatbuffers_thash_t)0x3ff5391c)
#define etm_SGraphInfo_type_identifier "\x1c\x39\xf5\x3f"
#ifndef etm_SGraphInfo_file_extension
#define etm_SGraphInfo_file_extension "bin"
#endif
#ifndef etm_Graph_file_identifier
#define etm_Graph_file_identifier 0
#endif
/* deprecated, use etm_Graph_file_identifier */
#ifndef etm_Graph_identifier
#define etm_Graph_identifier 0
#endif
#define etm_Graph_type_hash ((flatbuffers_thash_t)0x62b6e685)
#define etm_Graph_type_identifier "\x85\xe6\xb6\x62"
#ifndef etm_Graph_file_extension
#define etm_Graph_file_extension "bin"
#endif
#ifndef etm_Op_file_identifier
#define etm_Op_file_identifier 0
#endif
/* deprecated, use etm_Op_file_identifier */
#ifndef etm_Op_identifier
#define etm_Op_identifier 0
#endif
#define etm_Op_type_hash ((flatbuffers_thash_t)0xf35e35e8)
#define etm_Op_type_identifier "\xe8\x35\x5e\xf3"
#ifndef etm_Op_file_extension
#define etm_Op_file_extension "bin"
#endif
#ifndef etm_Model_file_identifier
#define etm_Model_file_identifier 0
#endif
/* deprecated, use etm_Model_file_identifier */
#ifndef etm_Model_identifier
#define etm_Model_identifier 0
#endif
#define etm_Model_type_hash ((flatbuffers_thash_t)0xc59c70f4)
#define etm_Model_type_identifier "\xf4\x70\x9c\xc5"
#ifndef etm_Model_file_extension
#define etm_Model_file_extension "bin"
#endif

typedef int32_t etm_TensorType_enum_t;
__flatbuffers_define_integer_type(etm_TensorType, etm_TensorType_enum_t, 32)
#define etm_TensorType_Undefined ((etm_TensorType_enum_t)INT32_C(0))
#define etm_TensorType_Bool ((etm_TensorType_enum_t)INT32_C(9))
#define etm_TensorType_Int8 ((etm_TensorType_enum_t)INT32_C(3))
#define etm_TensorType_Int16 ((etm_TensorType_enum_t)INT32_C(5))
#define etm_TensorType_Int32 ((etm_TensorType_enum_t)INT32_C(6))
#define etm_TensorType_Int64 ((etm_TensorType_enum_t)INT32_C(7))
#define etm_TensorType_Uint8 ((etm_TensorType_enum_t)INT32_C(2))
#define etm_TensorType_Uint16 ((etm_TensorType_enum_t)INT32_C(4))
#define etm_TensorType_Uint32 ((etm_TensorType_enum_t)INT32_C(12))
#define etm_TensorType_Uint64 ((etm_TensorType_enum_t)INT32_C(13))
#define etm_TensorType_Bfloat16 ((etm_TensorType_enum_t)INT32_C(16))
#define etm_TensorType_Float16 ((etm_TensorType_enum_t)INT32_C(10))
#define etm_TensorType_Float32 ((etm_TensorType_enum_t)INT32_C(1))
#define etm_TensorType_Float64 ((etm_TensorType_enum_t)INT32_C(11))
#define etm_TensorType_Complex64 ((etm_TensorType_enum_t)INT32_C(14))
#define etm_TensorType_Complex128 ((etm_TensorType_enum_t)INT32_C(15))
#define etm_TensorType_String ((etm_TensorType_enum_t)INT32_C(8))

static inline const char *etm_TensorType_name(etm_TensorType_enum_t value)
{
    switch (value) {
    case etm_TensorType_Undefined: return "Undefined";
    case etm_TensorType_Bool: return "Bool";
    case etm_TensorType_Int8: return "Int8";
    case etm_TensorType_Int16: return "Int16";
    case etm_TensorType_Int32: return "Int32";
    case etm_TensorType_Int64: return "Int64";
    case etm_TensorType_Uint8: return "Uint8";
    case etm_TensorType_Uint16: return "Uint16";
    case etm_TensorType_Uint32: return "Uint32";
    case etm_TensorType_Uint64: return "Uint64";
    case etm_TensorType_Bfloat16: return "Bfloat16";
    case etm_TensorType_Float16: return "Float16";
    case etm_TensorType_Float32: return "Float32";
    case etm_TensorType_Float64: return "Float64";
    case etm_TensorType_Complex64: return "Complex64";
    case etm_TensorType_Complex128: return "Complex128";
    case etm_TensorType_String: return "String";
    default: return "";
    }
}

static inline int etm_TensorType_is_known_value(etm_TensorType_enum_t value)
{
    switch (value) {
    case etm_TensorType_Undefined: return 1;
    case etm_TensorType_Bool: return 1;
    case etm_TensorType_Int8: return 1;
    case etm_TensorType_Int16: return 1;
    case etm_TensorType_Int32: return 1;
    case etm_TensorType_Int64: return 1;
    case etm_TensorType_Uint8: return 1;
    case etm_TensorType_Uint16: return 1;
    case etm_TensorType_Uint32: return 1;
    case etm_TensorType_Uint64: return 1;
    case etm_TensorType_Bfloat16: return 1;
    case etm_TensorType_Float16: return 1;
    case etm_TensorType_Float32: return 1;
    case etm_TensorType_Float64: return 1;
    case etm_TensorType_Complex64: return 1;
    case etm_TensorType_Complex128: return 1;
    case etm_TensorType_String: return 1;
    default: return 0;
    }
}

typedef int32_t etm_AttributeType_enum_t;
__flatbuffers_define_integer_type(etm_AttributeType, etm_AttributeType_enum_t, 32)
#define etm_AttributeType_Float ((etm_AttributeType_enum_t)INT32_C(0))
#define etm_AttributeType_Int ((etm_AttributeType_enum_t)INT32_C(1))
#define etm_AttributeType_String ((etm_AttributeType_enum_t)INT32_C(2))
#define etm_AttributeType_Tensor ((etm_AttributeType_enum_t)INT32_C(3))
#define etm_AttributeType_Graph ((etm_AttributeType_enum_t)INT32_C(4))
#define etm_AttributeType_Floats ((etm_AttributeType_enum_t)INT32_C(5))
#define etm_AttributeType_Int64s ((etm_AttributeType_enum_t)INT32_C(6))
#define etm_AttributeType_Tensors ((etm_AttributeType_enum_t)INT32_C(7))
#define etm_AttributeType_Graphs ((etm_AttributeType_enum_t)INT32_C(8))

static inline const char *etm_AttributeType_name(etm_AttributeType_enum_t value)
{
    switch (value) {
    case etm_AttributeType_Float: return "Float";
    case etm_AttributeType_Int: return "Int";
    case etm_AttributeType_String: return "String";
    case etm_AttributeType_Tensor: return "Tensor";
    case etm_AttributeType_Graph: return "Graph";
    case etm_AttributeType_Floats: return "Floats";
    case etm_AttributeType_Int64s: return "Int64s";
    case etm_AttributeType_Tensors: return "Tensors";
    case etm_AttributeType_Graphs: return "Graphs";
    default: return "";
    }
}

static inline int etm_AttributeType_is_known_value(etm_AttributeType_enum_t value)
{
    switch (value) {
    case etm_AttributeType_Float: return 1;
    case etm_AttributeType_Int: return 1;
    case etm_AttributeType_String: return 1;
    case etm_AttributeType_Tensor: return 1;
    case etm_AttributeType_Graph: return 1;
    case etm_AttributeType_Floats: return 1;
    case etm_AttributeType_Int64s: return 1;
    case etm_AttributeType_Tensors: return 1;
    case etm_AttributeType_Graphs: return 1;
    default: return 0;
    }
}

typedef int32_t etm_NodeType_enum_t;
__flatbuffers_define_integer_type(etm_NodeType, etm_NodeType_enum_t, 32)
#define etm_NodeType_Generic ((etm_NodeType_enum_t)INT32_C(0))
#define etm_NodeType_Input ((etm_NodeType_enum_t)INT32_C(1))
#define etm_NodeType_Output ((etm_NodeType_enum_t)INT32_C(2))
#define etm_NodeType_Hidden ((etm_NodeType_enum_t)INT32_C(3))

static inline const char *etm_NodeType_name(etm_NodeType_enum_t value)
{
    switch (value) {
    case etm_NodeType_Generic: return "Generic";
    case etm_NodeType_Input: return "Input";
    case etm_NodeType_Output: return "Output";
    case etm_NodeType_Hidden: return "Hidden";
    default: return "";
    }
}

static inline int etm_NodeType_is_known_value(etm_NodeType_enum_t value)
{
    switch (value) {
    case etm_NodeType_Generic: return 1;
    case etm_NodeType_Input: return 1;
    case etm_NodeType_Output: return 1;
    case etm_NodeType_Hidden: return 1;
    default: return 0;
    }
}

typedef int32_t etm_OpType_enum_t;
__flatbuffers_define_integer_type(etm_OpType, etm_OpType_enum_t, 32)
#define etm_OpType_Undefined ((etm_OpType_enum_t)INT32_C(0))
#define etm_OpType_Conv ((etm_OpType_enum_t)INT32_C(1))
#define etm_OpType_Pool ((etm_OpType_enum_t)INT32_C(2))

static inline const char *etm_OpType_name(etm_OpType_enum_t value)
{
    switch (value) {
    case etm_OpType_Undefined: return "Undefined";
    case etm_OpType_Conv: return "Conv";
    case etm_OpType_Pool: return "Pool";
    default: return "";
    }
}

static inline int etm_OpType_is_known_value(etm_OpType_enum_t value)
{
    switch (value) {
    case etm_OpType_Undefined: return 1;
    case etm_OpType_Conv: return 1;
    case etm_OpType_Pool: return 1;
    default: return 0;
    }
}



struct etm_Tensor_table { uint8_t unused__; };

static inline size_t etm_Tensor_vec_len(etm_Tensor_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Tensor_table_t etm_Tensor_vec_at(etm_Tensor_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Tensor_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Tensor)

__flatbuffers_define_scalar_field(0, etm_Tensor, type, etm_TensorType, etm_TensorType_enum_t, INT32_C(0))
__flatbuffers_define_string_field(1, etm_Tensor, name, 0)
__flatbuffers_define_scalar_field(2, etm_Tensor, index, flatbuffers_int32, int32_t, INT32_C(0))
__flatbuffers_define_vector_field(3, etm_Tensor, dims, flatbuffers_int32_vec_t, 0)
__flatbuffers_define_vector_field(4, etm_Tensor, datas, flatbuffers_uint8_vec_t, 0)
__flatbuffers_define_scalar_field(5, etm_Tensor, ndata, flatbuffers_uint64, uint64_t, UINT64_C(0))
__flatbuffers_define_scalar_field(6, etm_Tensor, szElem, flatbuffers_uint8, uint8_t, UINT8_C(0))
__flatbuffers_define_scalar_field(7, etm_Tensor, nElem, flatbuffers_uint32, uint32_t, UINT32_C(0))
__flatbuffers_define_scalar_field(8, etm_Tensor, pNode, flatbuffers_int16, int16_t, INT16_C(0))
__flatbuffers_define_scalar_field(9, etm_Tensor, isReshaped, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_scalar_field(10, etm_Tensor, isConstant, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_scalar_field(11, etm_Tensor, isInput, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_scalar_field(12, etm_Tensor, isOutput, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_scalar_field(13, etm_Tensor, isIallocated, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_scalar_field(14, etm_Tensor, layout, flatbuffers_uint16, uint16_t, UINT16_C(0))

struct etm_Attribute_table { uint8_t unused__; };

static inline size_t etm_Attribute_vec_len(etm_Attribute_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Attribute_table_t etm_Attribute_vec_at(etm_Attribute_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Attribute_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Attribute)

__flatbuffers_define_string_field(0, etm_Attribute, name, 0)
__flatbuffers_define_scalar_field(1, etm_Attribute, type, etm_AttributeType, etm_AttributeType_enum_t, INT32_C(0))
__flatbuffers_define_scalar_field(2, etm_Attribute, f, flatbuffers_float, float, 0.00000000f)
__flatbuffers_define_scalar_field(3, etm_Attribute, i, flatbuffers_int64, int64_t, INT64_C(0))
__flatbuffers_define_string_field(4, etm_Attribute, s, 0)
/* Skipping deprecated field: 'etm_Attribute_t' */

/* Skipping deprecated field: 'etm_Attribute_g' */

__flatbuffers_define_vector_field(7, etm_Attribute, fs, flatbuffers_float_vec_t, 0)
__flatbuffers_define_vector_field(8, etm_Attribute, is, flatbuffers_int64_vec_t, 0)
/* Skipping deprecated field: 'etm_Attribute_ts' */

/* Skipping deprecated field: 'etm_Attribute_gs' */


struct etm_Node_table { uint8_t unused__; };

static inline size_t etm_Node_vec_len(etm_Node_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Node_table_t etm_Node_vec_at(etm_Node_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Node_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Node)

__flatbuffers_define_string_field(0, etm_Node, name, 0)
__flatbuffers_define_scalar_field(1, etm_Node, index, flatbuffers_uint16, uint16_t, UINT16_C(0))
__flatbuffers_define_scalar_field(2, etm_Node, type, etm_NodeType, etm_NodeType_enum_t, INT32_C(0))
/* Skipping deprecated field: 'etm_Node_in' */

/* Skipping deprecated field: 'etm_Node_out' */

/* Skipping deprecated field: 'etm_Node_op' */

/* Skipping deprecated field: 'etm_Node_graph' */

__flatbuffers_define_vector_field(7, etm_Node, attrVec, etm_Attribute_vec_t, 0)
typedef uint8_t etm_GraphInfo_union_type_t;
__flatbuffers_define_integer_type(etm_GraphInfo, etm_GraphInfo_union_type_t, 8)
__flatbuffers_define_union(flatbuffers_, etm_GraphInfo)
#define etm_GraphInfo_NONE ((etm_GraphInfo_union_type_t)UINT8_C(0))
#define etm_GraphInfo_PGraphInfo ((etm_GraphInfo_union_type_t)UINT8_C(1))
#define etm_GraphInfo_SGraphInfo ((etm_GraphInfo_union_type_t)UINT8_C(2))

static inline const char *etm_GraphInfo_type_name(etm_GraphInfo_union_type_t type)
{
    switch (type) {
    case etm_GraphInfo_NONE: return "NONE";
    case etm_GraphInfo_PGraphInfo: return "PGraphInfo";
    case etm_GraphInfo_SGraphInfo: return "SGraphInfo";
    default: return "";
    }
}

static inline int etm_GraphInfo_is_known_type(etm_GraphInfo_union_type_t type)
{
    switch (type) {
    case etm_GraphInfo_NONE: return 1;
    case etm_GraphInfo_PGraphInfo: return 1;
    case etm_GraphInfo_SGraphInfo: return 1;
    default: return 0;
    }
}


struct etm_PGraphInfo_table { uint8_t unused__; };

static inline size_t etm_PGraphInfo_vec_len(etm_PGraphInfo_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_PGraphInfo_table_t etm_PGraphInfo_vec_at(etm_PGraphInfo_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_PGraphInfo_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_PGraphInfo)

__flatbuffers_define_vector_field(0, etm_PGraphInfo, subVec, etm_Graph_vec_t, 0)
__flatbuffers_define_vector_field(1, etm_PGraphInfo, inputInodesVec, flatbuffers_uint16_vec_t, 0)
__flatbuffers_define_vector_field(2, etm_PGraphInfo, outputInodesVec, flatbuffers_uint16_vec_t, 0)
__flatbuffers_define_scalar_field(3, etm_PGraphInfo, ninputNode, flatbuffers_uint16, uint16_t, UINT16_C(0))
__flatbuffers_define_scalar_field(4, etm_PGraphInfo, noutputNode, flatbuffers_uint16, uint16_t, UINT16_C(0))

struct etm_SGraphInfo_table { uint8_t unused__; };

static inline size_t etm_SGraphInfo_vec_len(etm_SGraphInfo_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_SGraphInfo_table_t etm_SGraphInfo_vec_at(etm_SGraphInfo_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_SGraphInfo_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_SGraphInfo)

__flatbuffers_define_scalar_field(0, etm_SGraphInfo, idx, flatbuffers_int32, int32_t, INT32_C(0))
__flatbuffers_define_vector_field(1, etm_SGraphInfo, nodesVec, flatbuffers_uint16_vec_t, 0)
__flatbuffers_define_vector_field(2, etm_SGraphInfo, inputItensorsVec, flatbuffers_uint16_vec_t, 0)
__flatbuffers_define_vector_field(3, etm_SGraphInfo, outputItensorsVec, flatbuffers_uint16_vec_t, 0)
/* Skipping deprecated field: 'etm_SGraphInfo_pgraph' */


struct etm_Graph_table { uint8_t unused__; };

static inline size_t etm_Graph_vec_len(etm_Graph_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Graph_table_t etm_Graph_vec_at(etm_Graph_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Graph_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Graph)

__flatbuffers_define_vector_field(0, etm_Graph, tensors, etm_Tensor_vec_t, 0)
__flatbuffers_define_vector_field(1, etm_Graph, nodes, etm_Node_vec_t, 0)
__flatbuffers_define_scalar_field(2, etm_Graph, dataLayout, flatbuffers_uint16, uint16_t, UINT16_C(0))
__flatbuffers_define_scalar_field(3, etm_Graph, isSub, flatbuffers_bool, flatbuffers_bool_t, UINT8_C(0))
__flatbuffers_define_union_field(flatbuffers_, 5, etm_Graph, more, etm_GraphInfo, 0)

struct etm_Op_table { uint8_t unused__; };

static inline size_t etm_Op_vec_len(etm_Op_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Op_table_t etm_Op_vec_at(etm_Op_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Op_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Op)

__flatbuffers_define_scalar_field(0, etm_Op, type, etm_OpType, etm_OpType_enum_t, INT32_C(0))
__flatbuffers_define_string_field(1, etm_Op, name, 0)
__flatbuffers_define_vector_field(2, etm_Op, inputIndexes, flatbuffers_int32_vec_t, 0)
__flatbuffers_define_vector_field(3, etm_Op, outputIndexs, flatbuffers_int32_vec_t, 0)

struct etm_Model_table { uint8_t unused__; };

static inline size_t etm_Model_vec_len(etm_Model_vec_t vec)
__flatbuffers_vec_len(vec)
static inline etm_Model_table_t etm_Model_vec_at(etm_Model_vec_t vec, size_t i)
__flatbuffers_offset_vec_at(etm_Model_table_t, vec, i, 0)
__flatbuffers_table_as_root(etm_Model)

__flatbuffers_define_string_field(0, etm_Model, name, 0)
__flatbuffers_define_vector_field(1, etm_Model, oplists, etm_Op_vec_t, 0)
__flatbuffers_define_vector_field(2, etm_Model, tensorName, flatbuffers_string_vec_t, 0)


#include "flatcc/flatcc_epilogue.h"
#endif /* ETM_READER_H */
#ifndef ETM_BUILDER_H
#define ETM_BUILDER_H

/* Generated by flatcc 0.6.2 FlatBuffers schema compiler for C by dvide.com */

#ifndef ETM_READER_H
#include "etm_reader.h"
#endif
#ifndef FLATBUFFERS_COMMON_BUILDER_H
#include "flatbuffers_common_builder.h"
#endif
#include "flatcc/flatcc_prologue.h"
#ifndef flatbuffers_identifier
#define flatbuffers_identifier 0
#endif
#ifndef flatbuffers_extension
#define flatbuffers_extension "bin"
#endif

#define __etm_TensorType_formal_args , etm_TensorType_enum_t v0
#define __etm_TensorType_call_args , v0
__flatbuffers_build_scalar(flatbuffers_, etm_TensorType, etm_TensorType_enum_t)
#define __etm_AttributeType_formal_args , etm_AttributeType_enum_t v0
#define __etm_AttributeType_call_args , v0
__flatbuffers_build_scalar(flatbuffers_, etm_AttributeType, etm_AttributeType_enum_t)
#define __etm_NodeType_formal_args , etm_NodeType_enum_t v0
#define __etm_NodeType_call_args , v0
__flatbuffers_build_scalar(flatbuffers_, etm_NodeType, etm_NodeType_enum_t)
#define __etm_OpType_formal_args , etm_OpType_enum_t v0
#define __etm_OpType_call_args , v0
__flatbuffers_build_scalar(flatbuffers_, etm_OpType, etm_OpType_enum_t)

typedef flatbuffers_union_ref_t etm_GraphInfo_union_ref_t;
typedef flatbuffers_union_vec_ref_t etm_GraphInfo_union_vec_ref_t;
static etm_GraphInfo_union_ref_t etm_GraphInfo_clone(flatbuffers_builder_t *B, etm_GraphInfo_union_t t);

static const flatbuffers_voffset_t __etm_Tensor_required[] = { 0 };
typedef flatbuffers_ref_t etm_Tensor_ref_t;
static etm_Tensor_ref_t etm_Tensor_clone(flatbuffers_builder_t *B, etm_Tensor_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Tensor, 15)

static const flatbuffers_voffset_t __etm_Attribute_required[] = { 0 };
typedef flatbuffers_ref_t etm_Attribute_ref_t;
static etm_Attribute_ref_t etm_Attribute_clone(flatbuffers_builder_t *B, etm_Attribute_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Attribute, 11)

static const flatbuffers_voffset_t __etm_Node_required[] = { 0 };
typedef flatbuffers_ref_t etm_Node_ref_t;
static etm_Node_ref_t etm_Node_clone(flatbuffers_builder_t *B, etm_Node_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Node, 8)

static const flatbuffers_voffset_t __etm_PGraphInfo_required[] = { 0 };
typedef flatbuffers_ref_t etm_PGraphInfo_ref_t;
static etm_PGraphInfo_ref_t etm_PGraphInfo_clone(flatbuffers_builder_t *B, etm_PGraphInfo_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_PGraphInfo, 5)

static const flatbuffers_voffset_t __etm_SGraphInfo_required[] = { 0 };
typedef flatbuffers_ref_t etm_SGraphInfo_ref_t;
static etm_SGraphInfo_ref_t etm_SGraphInfo_clone(flatbuffers_builder_t *B, etm_SGraphInfo_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_SGraphInfo, 5)

static const flatbuffers_voffset_t __etm_Graph_required[] = { 0 };
typedef flatbuffers_ref_t etm_Graph_ref_t;
static etm_Graph_ref_t etm_Graph_clone(flatbuffers_builder_t *B, etm_Graph_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Graph, 6)

static const flatbuffers_voffset_t __etm_Op_required[] = { 0 };
typedef flatbuffers_ref_t etm_Op_ref_t;
static etm_Op_ref_t etm_Op_clone(flatbuffers_builder_t *B, etm_Op_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Op, 4)

static const flatbuffers_voffset_t __etm_Model_required[] = { 0 };
typedef flatbuffers_ref_t etm_Model_ref_t;
static etm_Model_ref_t etm_Model_clone(flatbuffers_builder_t *B, etm_Model_table_t t);
__flatbuffers_build_table(flatbuffers_, etm_Model, 3)

#define __etm_Tensor_formal_args ,\
  etm_TensorType_enum_t v0, flatbuffers_string_ref_t v1, int32_t v2, flatbuffers_int32_vec_ref_t v3,\
  flatbuffers_uint8_vec_ref_t v4, uint64_t v5, uint8_t v6, uint32_t v7,\
  int16_t v8, flatbuffers_bool_t v9, flatbuffers_bool_t v10, flatbuffers_bool_t v11,\
  flatbuffers_bool_t v12, flatbuffers_bool_t v13, uint16_t v14
#define __etm_Tensor_call_args ,\
  v0, v1, v2, v3,\
  v4, v5, v6, v7,\
  v8, v9, v10, v11,\
  v12, v13, v14
static inline etm_Tensor_ref_t etm_Tensor_create(flatbuffers_builder_t *B __etm_Tensor_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Tensor, etm_Tensor_file_identifier, etm_Tensor_type_identifier)

#define __etm_Attribute_formal_args ,\
  flatbuffers_string_ref_t v0, etm_AttributeType_enum_t v1, float v2, int64_t v3,\
  flatbuffers_string_ref_t v4, flatbuffers_float_vec_ref_t v7, flatbuffers_int64_vec_ref_t v8
#define __etm_Attribute_call_args ,\
  v0, v1, v2, v3,\
  v4, v7, v8
static inline etm_Attribute_ref_t etm_Attribute_create(flatbuffers_builder_t *B __etm_Attribute_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Attribute, etm_Attribute_file_identifier, etm_Attribute_type_identifier)

#define __etm_Node_formal_args , flatbuffers_string_ref_t v0, uint16_t v1, etm_NodeType_enum_t v2, etm_Attribute_vec_ref_t v7
#define __etm_Node_call_args , v0, v1, v2, v7
static inline etm_Node_ref_t etm_Node_create(flatbuffers_builder_t *B __etm_Node_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Node, etm_Node_file_identifier, etm_Node_type_identifier)

#define __etm_PGraphInfo_formal_args ,\
  etm_Graph_vec_ref_t v0, flatbuffers_uint16_vec_ref_t v1, flatbuffers_uint16_vec_ref_t v2, uint16_t v3, uint16_t v4
#define __etm_PGraphInfo_call_args ,\
  v0, v1, v2, v3, v4
static inline etm_PGraphInfo_ref_t etm_PGraphInfo_create(flatbuffers_builder_t *B __etm_PGraphInfo_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_PGraphInfo, etm_PGraphInfo_file_identifier, etm_PGraphInfo_type_identifier)

#define __etm_SGraphInfo_formal_args , int32_t v0, flatbuffers_uint16_vec_ref_t v1, flatbuffers_uint16_vec_ref_t v2, flatbuffers_uint16_vec_ref_t v3
#define __etm_SGraphInfo_call_args , v0, v1, v2, v3
static inline etm_SGraphInfo_ref_t etm_SGraphInfo_create(flatbuffers_builder_t *B __etm_SGraphInfo_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_SGraphInfo, etm_SGraphInfo_file_identifier, etm_SGraphInfo_type_identifier)

#define __etm_Graph_formal_args ,\
  etm_Tensor_vec_ref_t v0, etm_Node_vec_ref_t v1, uint16_t v2, flatbuffers_bool_t v3, etm_GraphInfo_union_ref_t v5
#define __etm_Graph_call_args ,\
  v0, v1, v2, v3, v5
static inline etm_Graph_ref_t etm_Graph_create(flatbuffers_builder_t *B __etm_Graph_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Graph, etm_Graph_file_identifier, etm_Graph_type_identifier)

#define __etm_Op_formal_args , etm_OpType_enum_t v0, flatbuffers_string_ref_t v1, flatbuffers_int32_vec_ref_t v2, flatbuffers_int32_vec_ref_t v3
#define __etm_Op_call_args , v0, v1, v2, v3
static inline etm_Op_ref_t etm_Op_create(flatbuffers_builder_t *B __etm_Op_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Op, etm_Op_file_identifier, etm_Op_type_identifier)

#define __etm_Model_formal_args , flatbuffers_string_ref_t v0, etm_Op_vec_ref_t v1, flatbuffers_string_vec_ref_t v2
#define __etm_Model_call_args , v0, v1, v2
static inline etm_Model_ref_t etm_Model_create(flatbuffers_builder_t *B __etm_Model_formal_args);
__flatbuffers_build_table_prolog(flatbuffers_, etm_Model, etm_Model_file_identifier, etm_Model_type_identifier)

static inline etm_GraphInfo_union_ref_t etm_GraphInfo_as_NONE(void)
{ etm_GraphInfo_union_ref_t uref; uref.type = etm_GraphInfo_NONE; uref.value = 0; return uref; }
static inline etm_GraphInfo_union_ref_t etm_GraphInfo_as_PGraphInfo(etm_PGraphInfo_ref_t ref)
{ etm_GraphInfo_union_ref_t uref; uref.type = etm_GraphInfo_PGraphInfo; uref.value = ref; return uref; }
static inline etm_GraphInfo_union_ref_t etm_GraphInfo_as_SGraphInfo(etm_SGraphInfo_ref_t ref)
{ etm_GraphInfo_union_ref_t uref; uref.type = etm_GraphInfo_SGraphInfo; uref.value = ref; return uref; }
__flatbuffers_build_union_vector(flatbuffers_, etm_GraphInfo)

static etm_GraphInfo_union_ref_t etm_GraphInfo_clone(flatbuffers_builder_t *B, etm_GraphInfo_union_t u)
{
    switch (u.type) {
    case 1: return etm_GraphInfo_as_PGraphInfo(etm_PGraphInfo_clone(B, (etm_PGraphInfo_table_t)u.value));
    case 2: return etm_GraphInfo_as_SGraphInfo(etm_SGraphInfo_clone(B, (etm_SGraphInfo_table_t)u.value));
    default: return etm_GraphInfo_as_NONE();
    }
}

__flatbuffers_build_scalar_field(0, flatbuffers_, etm_Tensor_type, etm_TensorType, etm_TensorType_enum_t, 4, 4, INT32_C(0), etm_Tensor)
__flatbuffers_build_string_field(1, flatbuffers_, etm_Tensor_name, etm_Tensor)
__flatbuffers_build_scalar_field(2, flatbuffers_, etm_Tensor_index, flatbuffers_int32, int32_t, 4, 4, INT32_C(0), etm_Tensor)
__flatbuffers_build_vector_field(3, flatbuffers_, etm_Tensor_dims, flatbuffers_int32, int32_t, etm_Tensor)
__flatbuffers_build_vector_field(4, flatbuffers_, etm_Tensor_datas, flatbuffers_uint8, uint8_t, etm_Tensor)
__flatbuffers_build_scalar_field(5, flatbuffers_, etm_Tensor_ndata, flatbuffers_uint64, uint64_t, 8, 8, UINT64_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(6, flatbuffers_, etm_Tensor_szElem, flatbuffers_uint8, uint8_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(7, flatbuffers_, etm_Tensor_nElem, flatbuffers_uint32, uint32_t, 4, 4, UINT32_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(8, flatbuffers_, etm_Tensor_pNode, flatbuffers_int16, int16_t, 2, 2, INT16_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(9, flatbuffers_, etm_Tensor_isReshaped, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(10, flatbuffers_, etm_Tensor_isConstant, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(11, flatbuffers_, etm_Tensor_isInput, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(12, flatbuffers_, etm_Tensor_isOutput, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(13, flatbuffers_, etm_Tensor_isIallocated, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Tensor)
__flatbuffers_build_scalar_field(14, flatbuffers_, etm_Tensor_layout, flatbuffers_uint16, uint16_t, 2, 2, UINT16_C(0), etm_Tensor)

static inline etm_Tensor_ref_t etm_Tensor_create(flatbuffers_builder_t *B __etm_Tensor_formal_args)
{
    if (etm_Tensor_start(B)
        || etm_Tensor_ndata_add(B, v5)
        || etm_Tensor_type_add(B, v0)
        || etm_Tensor_name_add(B, v1)
        || etm_Tensor_index_add(B, v2)
        || etm_Tensor_dims_add(B, v3)
        || etm_Tensor_datas_add(B, v4)
        || etm_Tensor_nElem_add(B, v7)
        || etm_Tensor_pNode_add(B, v8)
        || etm_Tensor_layout_add(B, v14)
        || etm_Tensor_szElem_add(B, v6)
        || etm_Tensor_isReshaped_add(B, v9)
        || etm_Tensor_isConstant_add(B, v10)
        || etm_Tensor_isInput_add(B, v11)
        || etm_Tensor_isOutput_add(B, v12)
        || etm_Tensor_isIallocated_add(B, v13)) {
        return 0;
    }
    return etm_Tensor_end(B);
}

static etm_Tensor_ref_t etm_Tensor_clone(flatbuffers_builder_t *B, etm_Tensor_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Tensor_start(B)
        || etm_Tensor_ndata_pick(B, t)
        || etm_Tensor_type_pick(B, t)
        || etm_Tensor_name_pick(B, t)
        || etm_Tensor_index_pick(B, t)
        || etm_Tensor_dims_pick(B, t)
        || etm_Tensor_datas_pick(B, t)
        || etm_Tensor_nElem_pick(B, t)
        || etm_Tensor_pNode_pick(B, t)
        || etm_Tensor_layout_pick(B, t)
        || etm_Tensor_szElem_pick(B, t)
        || etm_Tensor_isReshaped_pick(B, t)
        || etm_Tensor_isConstant_pick(B, t)
        || etm_Tensor_isInput_pick(B, t)
        || etm_Tensor_isOutput_pick(B, t)
        || etm_Tensor_isIallocated_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Tensor_end(B));
}

__flatbuffers_build_string_field(0, flatbuffers_, etm_Attribute_name, etm_Attribute)
__flatbuffers_build_scalar_field(1, flatbuffers_, etm_Attribute_type, etm_AttributeType, etm_AttributeType_enum_t, 4, 4, INT32_C(0), etm_Attribute)
__flatbuffers_build_scalar_field(2, flatbuffers_, etm_Attribute_f, flatbuffers_float, float, 4, 4, 0.00000000f, etm_Attribute)
__flatbuffers_build_scalar_field(3, flatbuffers_, etm_Attribute_i, flatbuffers_int64, int64_t, 8, 8, INT64_C(0), etm_Attribute)
__flatbuffers_build_string_field(4, flatbuffers_, etm_Attribute_s, etm_Attribute)
/* Skipping build of deprecated field: 'etm_Attribute_t' */

/* Skipping build of deprecated field: 'etm_Attribute_g' */

__flatbuffers_build_vector_field(7, flatbuffers_, etm_Attribute_fs, flatbuffers_float, float, etm_Attribute)
__flatbuffers_build_vector_field(8, flatbuffers_, etm_Attribute_is, flatbuffers_int64, int64_t, etm_Attribute)
/* Skipping build of deprecated field: 'etm_Attribute_ts' */

/* Skipping build of deprecated field: 'etm_Attribute_gs' */


static inline etm_Attribute_ref_t etm_Attribute_create(flatbuffers_builder_t *B __etm_Attribute_formal_args)
{
    if (etm_Attribute_start(B)
        || etm_Attribute_i_add(B, v3)
        || etm_Attribute_name_add(B, v0)
        || etm_Attribute_type_add(B, v1)
        || etm_Attribute_f_add(B, v2)
        || etm_Attribute_s_add(B, v4)
        || etm_Attribute_fs_add(B, v7)
        || etm_Attribute_is_add(B, v8)) {
        return 0;
    }
    return etm_Attribute_end(B);
}

static etm_Attribute_ref_t etm_Attribute_clone(flatbuffers_builder_t *B, etm_Attribute_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Attribute_start(B)
        || etm_Attribute_i_pick(B, t)
        || etm_Attribute_name_pick(B, t)
        || etm_Attribute_type_pick(B, t)
        || etm_Attribute_f_pick(B, t)
        || etm_Attribute_s_pick(B, t)
        || etm_Attribute_fs_pick(B, t)
        || etm_Attribute_is_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Attribute_end(B));
}

__flatbuffers_build_string_field(0, flatbuffers_, etm_Node_name, etm_Node)
__flatbuffers_build_scalar_field(1, flatbuffers_, etm_Node_index, flatbuffers_uint16, uint16_t, 2, 2, UINT16_C(0), etm_Node)
__flatbuffers_build_scalar_field(2, flatbuffers_, etm_Node_type, etm_NodeType, etm_NodeType_enum_t, 4, 4, INT32_C(0), etm_Node)
/* Skipping build of deprecated field: 'etm_Node_in' */

/* Skipping build of deprecated field: 'etm_Node_out' */

/* Skipping build of deprecated field: 'etm_Node_op' */

/* Skipping build of deprecated field: 'etm_Node_graph' */

__flatbuffers_build_table_vector_field(7, flatbuffers_, etm_Node_attrVec, etm_Attribute, etm_Node)

static inline etm_Node_ref_t etm_Node_create(flatbuffers_builder_t *B __etm_Node_formal_args)
{
    if (etm_Node_start(B)
        || etm_Node_name_add(B, v0)
        || etm_Node_type_add(B, v2)
        || etm_Node_attrVec_add(B, v7)
        || etm_Node_index_add(B, v1)) {
        return 0;
    }
    return etm_Node_end(B);
}

static etm_Node_ref_t etm_Node_clone(flatbuffers_builder_t *B, etm_Node_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Node_start(B)
        || etm_Node_name_pick(B, t)
        || etm_Node_type_pick(B, t)
        || etm_Node_attrVec_pick(B, t)
        || etm_Node_index_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Node_end(B));
}

__flatbuffers_build_table_vector_field(0, flatbuffers_, etm_PGraphInfo_subVec, etm_Graph, etm_PGraphInfo)
__flatbuffers_build_vector_field(1, flatbuffers_, etm_PGraphInfo_inputInodesVec, flatbuffers_uint16, uint16_t, etm_PGraphInfo)
__flatbuffers_build_vector_field(2, flatbuffers_, etm_PGraphInfo_outputInodesVec, flatbuffers_uint16, uint16_t, etm_PGraphInfo)
__flatbuffers_build_scalar_field(3, flatbuffers_, etm_PGraphInfo_ninputNode, flatbuffers_uint16, uint16_t, 2, 2, UINT16_C(0), etm_PGraphInfo)
__flatbuffers_build_scalar_field(4, flatbuffers_, etm_PGraphInfo_noutputNode, flatbuffers_uint16, uint16_t, 2, 2, UINT16_C(0), etm_PGraphInfo)

static inline etm_PGraphInfo_ref_t etm_PGraphInfo_create(flatbuffers_builder_t *B __etm_PGraphInfo_formal_args)
{
    if (etm_PGraphInfo_start(B)
        || etm_PGraphInfo_subVec_add(B, v0)
        || etm_PGraphInfo_inputInodesVec_add(B, v1)
        || etm_PGraphInfo_outputInodesVec_add(B, v2)
        || etm_PGraphInfo_ninputNode_add(B, v3)
        || etm_PGraphInfo_noutputNode_add(B, v4)) {
        return 0;
    }
    return etm_PGraphInfo_end(B);
}

static etm_PGraphInfo_ref_t etm_PGraphInfo_clone(flatbuffers_builder_t *B, etm_PGraphInfo_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_PGraphInfo_start(B)
        || etm_PGraphInfo_subVec_pick(B, t)
        || etm_PGraphInfo_inputInodesVec_pick(B, t)
        || etm_PGraphInfo_outputInodesVec_pick(B, t)
        || etm_PGraphInfo_ninputNode_pick(B, t)
        || etm_PGraphInfo_noutputNode_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_PGraphInfo_end(B));
}

__flatbuffers_build_scalar_field(0, flatbuffers_, etm_SGraphInfo_idx, flatbuffers_int32, int32_t, 4, 4, INT32_C(0), etm_SGraphInfo)
__flatbuffers_build_vector_field(1, flatbuffers_, etm_SGraphInfo_nodesVec, flatbuffers_uint16, uint16_t, etm_SGraphInfo)
__flatbuffers_build_vector_field(2, flatbuffers_, etm_SGraphInfo_inputItensorsVec, flatbuffers_uint16, uint16_t, etm_SGraphInfo)
__flatbuffers_build_vector_field(3, flatbuffers_, etm_SGraphInfo_outputItensorsVec, flatbuffers_uint16, uint16_t, etm_SGraphInfo)
/* Skipping build of deprecated field: 'etm_SGraphInfo_pgraph' */


static inline etm_SGraphInfo_ref_t etm_SGraphInfo_create(flatbuffers_builder_t *B __etm_SGraphInfo_formal_args)
{
    if (etm_SGraphInfo_start(B)
        || etm_SGraphInfo_idx_add(B, v0)
        || etm_SGraphInfo_nodesVec_add(B, v1)
        || etm_SGraphInfo_inputItensorsVec_add(B, v2)
        || etm_SGraphInfo_outputItensorsVec_add(B, v3)) {
        return 0;
    }
    return etm_SGraphInfo_end(B);
}

static etm_SGraphInfo_ref_t etm_SGraphInfo_clone(flatbuffers_builder_t *B, etm_SGraphInfo_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_SGraphInfo_start(B)
        || etm_SGraphInfo_idx_pick(B, t)
        || etm_SGraphInfo_nodesVec_pick(B, t)
        || etm_SGraphInfo_inputItensorsVec_pick(B, t)
        || etm_SGraphInfo_outputItensorsVec_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_SGraphInfo_end(B));
}

__flatbuffers_build_table_vector_field(0, flatbuffers_, etm_Graph_tensors, etm_Tensor, etm_Graph)
__flatbuffers_build_table_vector_field(1, flatbuffers_, etm_Graph_nodes, etm_Node, etm_Graph)
__flatbuffers_build_scalar_field(2, flatbuffers_, etm_Graph_dataLayout, flatbuffers_uint16, uint16_t, 2, 2, UINT16_C(0), etm_Graph)
__flatbuffers_build_scalar_field(3, flatbuffers_, etm_Graph_isSub, flatbuffers_bool, flatbuffers_bool_t, 1, 1, UINT8_C(0), etm_Graph)
__flatbuffers_build_union_field(5, flatbuffers_, etm_Graph_more, etm_GraphInfo, etm_Graph)
__flatbuffers_build_union_table_value_field(flatbuffers_, etm_Graph_more, etm_GraphInfo, PGraphInfo, etm_PGraphInfo)
__flatbuffers_build_union_table_value_field(flatbuffers_, etm_Graph_more, etm_GraphInfo, SGraphInfo, etm_SGraphInfo)

static inline etm_Graph_ref_t etm_Graph_create(flatbuffers_builder_t *B __etm_Graph_formal_args)
{
    if (etm_Graph_start(B)
        || etm_Graph_tensors_add(B, v0)
        || etm_Graph_nodes_add(B, v1)
        || etm_Graph_more_add_value(B, v5)
        || etm_Graph_dataLayout_add(B, v2)
        || etm_Graph_isSub_add(B, v3)
        || etm_Graph_more_add_type(B, v5.type)) {
        return 0;
    }
    return etm_Graph_end(B);
}

static etm_Graph_ref_t etm_Graph_clone(flatbuffers_builder_t *B, etm_Graph_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Graph_start(B)
        || etm_Graph_tensors_pick(B, t)
        || etm_Graph_nodes_pick(B, t)
        || etm_Graph_more_pick(B, t)
        || etm_Graph_dataLayout_pick(B, t)
        || etm_Graph_isSub_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Graph_end(B));
}

__flatbuffers_build_scalar_field(0, flatbuffers_, etm_Op_type, etm_OpType, etm_OpType_enum_t, 4, 4, INT32_C(0), etm_Op)
__flatbuffers_build_string_field(1, flatbuffers_, etm_Op_name, etm_Op)
__flatbuffers_build_vector_field(2, flatbuffers_, etm_Op_inputIndexes, flatbuffers_int32, int32_t, etm_Op)
__flatbuffers_build_vector_field(3, flatbuffers_, etm_Op_outputIndexs, flatbuffers_int32, int32_t, etm_Op)

static inline etm_Op_ref_t etm_Op_create(flatbuffers_builder_t *B __etm_Op_formal_args)
{
    if (etm_Op_start(B)
        || etm_Op_type_add(B, v0)
        || etm_Op_name_add(B, v1)
        || etm_Op_inputIndexes_add(B, v2)
        || etm_Op_outputIndexs_add(B, v3)) {
        return 0;
    }
    return etm_Op_end(B);
}

static etm_Op_ref_t etm_Op_clone(flatbuffers_builder_t *B, etm_Op_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Op_start(B)
        || etm_Op_type_pick(B, t)
        || etm_Op_name_pick(B, t)
        || etm_Op_inputIndexes_pick(B, t)
        || etm_Op_outputIndexs_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Op_end(B));
}

__flatbuffers_build_string_field(0, flatbuffers_, etm_Model_name, etm_Model)
__flatbuffers_build_table_vector_field(1, flatbuffers_, etm_Model_oplists, etm_Op, etm_Model)
__flatbuffers_build_string_vector_field(2, flatbuffers_, etm_Model_tensorName, etm_Model)

static inline etm_Model_ref_t etm_Model_create(flatbuffers_builder_t *B __etm_Model_formal_args)
{
    if (etm_Model_start(B)
        || etm_Model_name_add(B, v0)
        || etm_Model_oplists_add(B, v1)
        || etm_Model_tensorName_add(B, v2)) {
        return 0;
    }
    return etm_Model_end(B);
}

static etm_Model_ref_t etm_Model_clone(flatbuffers_builder_t *B, etm_Model_table_t t)
{
    __flatbuffers_memoize_begin(B, t);
    if (etm_Model_start(B)
        || etm_Model_name_pick(B, t)
        || etm_Model_oplists_pick(B, t)
        || etm_Model_tensorName_pick(B, t)) {
        return 0;
    }
    __flatbuffers_memoize_end(B, t, etm_Model_end(B));
}

#include "flatcc/flatcc_epilogue.h"
#endif /* ETM_BUILDER_H */
#ifndef ETM_VERIFIER_H
#define ETM_VERIFIER_H

/* Generated by flatcc 0.6.2 FlatBuffers schema compiler for C by dvide.com */

#ifndef ETM_READER_H
#include "etm_reader.h"
#endif
#include "flatcc/flatcc_verifier.h"
#include "flatcc/flatcc_prologue.h"

static int etm_Tensor_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_Attribute_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_Node_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_PGraphInfo_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_SGraphInfo_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_Graph_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_Op_verify_table(flatcc_table_verifier_descriptor_t *td);
static int etm_Model_verify_table(flatcc_table_verifier_descriptor_t *td);

static int etm_GraphInfo_union_verifier(flatcc_union_verifier_descriptor_t *ud)
{
    switch (ud->type) {
    case 1: return flatcc_verify_union_table(ud, etm_PGraphInfo_verify_table); /* PGraphInfo */
    case 2: return flatcc_verify_union_table(ud, etm_SGraphInfo_verify_table); /* SGraphInfo */
    default: return flatcc_verify_ok;
    }
}

static int etm_Tensor_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_field(td, 0, 4, 4) /* type */)) return ret;
    if ((ret = flatcc_verify_string_field(td, 1, 0) /* name */)) return ret;
    if ((ret = flatcc_verify_field(td, 2, 4, 4) /* index */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 3, 0, 4, 4, INT64_C(1073741823)) /* dims */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 4, 0, 1, 1, INT64_C(4294967295)) /* datas */)) return ret;
    if ((ret = flatcc_verify_field(td, 5, 8, 8) /* ndata */)) return ret;
    if ((ret = flatcc_verify_field(td, 6, 1, 1) /* szElem */)) return ret;
    if ((ret = flatcc_verify_field(td, 7, 4, 4) /* nElem */)) return ret;
    if ((ret = flatcc_verify_field(td, 8, 2, 2) /* pNode */)) return ret;
    if ((ret = flatcc_verify_field(td, 9, 1, 1) /* isReshaped */)) return ret;
    if ((ret = flatcc_verify_field(td, 10, 1, 1) /* isConstant */)) return ret;
    if ((ret = flatcc_verify_field(td, 11, 1, 1) /* isInput */)) return ret;
    if ((ret = flatcc_verify_field(td, 12, 1, 1) /* isOutput */)) return ret;
    if ((ret = flatcc_verify_field(td, 13, 1, 1) /* isIallocated */)) return ret;
    if ((ret = flatcc_verify_field(td, 14, 2, 2) /* layout */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Tensor_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Tensor_identifier, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Tensor_identifier, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Tensor_type_identifier, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Tensor_type_identifier, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Tensor_verify_table);
}

static inline int etm_Tensor_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Tensor_verify_table);
}

static int etm_Attribute_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_string_field(td, 0, 0) /* name */)) return ret;
    if ((ret = flatcc_verify_field(td, 1, 4, 4) /* type */)) return ret;
    if ((ret = flatcc_verify_field(td, 2, 4, 4) /* f */)) return ret;
    if ((ret = flatcc_verify_field(td, 3, 8, 8) /* i */)) return ret;
    if ((ret = flatcc_verify_string_field(td, 4, 0) /* s */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 7, 0, 4, 4, INT64_C(1073741823)) /* fs */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 8, 0, 8, 8, INT64_C(536870911)) /* is */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Attribute_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Attribute_identifier, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Attribute_identifier, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Attribute_type_identifier, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Attribute_type_identifier, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Attribute_verify_table);
}

static inline int etm_Attribute_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Attribute_verify_table);
}

static int etm_Node_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_string_field(td, 0, 0) /* name */)) return ret;
    if ((ret = flatcc_verify_field(td, 1, 2, 2) /* index */)) return ret;
    if ((ret = flatcc_verify_field(td, 2, 4, 4) /* type */)) return ret;
    if ((ret = flatcc_verify_table_vector_field(td, 7, 0, &etm_Attribute_verify_table) /* attrVec */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Node_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Node_identifier, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Node_identifier, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Node_type_identifier, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Node_type_identifier, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Node_verify_table);
}

static inline int etm_Node_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Node_verify_table);
}

static int etm_PGraphInfo_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_table_vector_field(td, 0, 0, &etm_Graph_verify_table) /* subVec */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 1, 0, 2, 2, INT64_C(2147483647)) /* inputInodesVec */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 2, 0, 2, 2, INT64_C(2147483647)) /* outputInodesVec */)) return ret;
    if ((ret = flatcc_verify_field(td, 3, 2, 2) /* ninputNode */)) return ret;
    if ((ret = flatcc_verify_field(td, 4, 2, 2) /* noutputNode */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_PGraphInfo_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_PGraphInfo_identifier, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_PGraphInfo_identifier, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_PGraphInfo_type_identifier, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_PGraphInfo_type_identifier, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_PGraphInfo_verify_table);
}

static inline int etm_PGraphInfo_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_PGraphInfo_verify_table);
}

static int etm_SGraphInfo_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_field(td, 0, 4, 4) /* idx */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 1, 0, 2, 2, INT64_C(2147483647)) /* nodesVec */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 2, 0, 2, 2, INT64_C(2147483647)) /* inputItensorsVec */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 3, 0, 2, 2, INT64_C(2147483647)) /* outputItensorsVec */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_SGraphInfo_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_SGraphInfo_identifier, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_SGraphInfo_identifier, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_SGraphInfo_type_identifier, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_SGraphInfo_type_identifier, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_SGraphInfo_verify_table);
}

static inline int etm_SGraphInfo_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_SGraphInfo_verify_table);
}

static int etm_Graph_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_table_vector_field(td, 0, 0, &etm_Tensor_verify_table) /* tensors */)) return ret;
    if ((ret = flatcc_verify_table_vector_field(td, 1, 0, &etm_Node_verify_table) /* nodes */)) return ret;
    if ((ret = flatcc_verify_field(td, 2, 2, 2) /* dataLayout */)) return ret;
    if ((ret = flatcc_verify_field(td, 3, 1, 1) /* isSub */)) return ret;
    if ((ret = flatcc_verify_union_field(td, 5, 0, &etm_GraphInfo_union_verifier) /* more */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Graph_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Graph_identifier, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Graph_identifier, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Graph_type_identifier, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Graph_type_identifier, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Graph_verify_table);
}

static inline int etm_Graph_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Graph_verify_table);
}

static int etm_Op_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_field(td, 0, 4, 4) /* type */)) return ret;
    if ((ret = flatcc_verify_string_field(td, 1, 0) /* name */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 2, 0, 4, 4, INT64_C(1073741823)) /* inputIndexes */)) return ret;
    if ((ret = flatcc_verify_vector_field(td, 3, 0, 4, 4, INT64_C(1073741823)) /* outputIndexs */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Op_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Op_identifier, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Op_identifier, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Op_type_identifier, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Op_type_identifier, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Op_verify_table);
}

static inline int etm_Op_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Op_verify_table);
}

static int etm_Model_verify_table(flatcc_table_verifier_descriptor_t *td)
{
    int ret;
    if ((ret = flatcc_verify_string_field(td, 0, 0) /* name */)) return ret;
    if ((ret = flatcc_verify_table_vector_field(td, 1, 0, &etm_Op_verify_table) /* oplists */)) return ret;
    if ((ret = flatcc_verify_string_vector_field(td, 2, 0) /* tensorName */)) return ret;
    return flatcc_verify_ok;
}

static inline int etm_Model_verify_as_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Model_identifier, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Model_identifier, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_typed_root(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root(buf, bufsiz, etm_Model_type_identifier, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_typed_root_with_size(const void *buf, size_t bufsiz)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, etm_Model_type_identifier, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_root_with_identifier(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root(buf, bufsiz, fid, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_root_with_identifier_and_size(const void *buf, size_t bufsiz, const char *fid)
{
    return flatcc_verify_table_as_root_with_size(buf, bufsiz, fid, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_root_with_type_hash(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root(buf, bufsiz, thash, &etm_Model_verify_table);
}

static inline int etm_Model_verify_as_root_with_type_hash_and_size(const void *buf, size_t bufsiz, flatbuffers_thash_t thash)
{
    return flatcc_verify_table_as_typed_root_with_size(buf, bufsiz, thash, &etm_Model_verify_table);
}

#include "flatcc/flatcc_epilogue.h"
#endif /* ETM_VERIFIER_H */
